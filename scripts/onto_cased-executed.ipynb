{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a840269-1836-4e2f-b68f-cf051f8fb4bc",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T14:59:16.259766Z",
     "iopub.status.busy": "2025-06-14T14:59:16.259403Z",
     "iopub.status.idle": "2025-06-14T15:00:59.265084Z",
     "shell.execute_reply": "2025-06-14T15:00:59.264410Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from nameparser import HumanName\n",
    "from names_dataset import NameDataset, NameWrapper\n",
    "from ethnicseer import EthnicClassifier\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pycountry_convert as pc\n",
    "import pycountry\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, cohen_kappa_score\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from datasets import ClassLabel\n",
    "from evaluate import load as load_metric\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7573e05-e012-4aad-8cc8-cf1059f36e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.268033Z",
     "iopub.status.busy": "2025-06-14T15:00:59.267238Z",
     "iopub.status.idle": "2025-06-14T15:00:59.271037Z",
     "shell.execute_reply": "2025-06-14T15:00:59.270636Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9aad505-c3e4-4097-9cbb-a52fd4904934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.272866Z",
     "iopub.status.busy": "2025-06-14T15:00:59.272380Z",
     "iopub.status.idle": "2025-06-14T15:00:59.424989Z",
     "shell.execute_reply": "2025-06-14T15:00:59.424243Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = load_from_disk(\"./splits/conll_main\")\n",
    "\n",
    "ontonotes_main = load_from_disk(\"./splits/ontonotes_main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c4f89-dbd0-41cf-94ea-65816c3250ca",
   "metadata": {},
   "source": [
    "# Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28293a63-0d2c-4656-9288-8872aa08c838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.427328Z",
     "iopub.status.busy": "2025-06-14T15:00:59.426961Z",
     "iopub.status.idle": "2025-06-14T15:00:59.490059Z",
     "shell.execute_reply": "2025-06-14T15:00:59.489514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b951be-37ac-4db8-bcc5-945356c8bc33",
   "metadata": {},
   "source": [
    "# Tokenisation & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41793608-572c-473b-b770-1cda88a2f950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.492033Z",
     "iopub.status.busy": "2025-06-14T15:00:59.491681Z",
     "iopub.status.idle": "2025-06-14T15:00:59.496203Z",
     "shell.execute_reply": "2025-06-14T15:00:59.495814Z"
    }
   },
   "outputs": [],
   "source": [
    "ontonotes_id_to_label = {\n",
    "    0: \"O\", 1: \"B-CARDINAL\", 2: \"B-DATE\", 3: \"I-DATE\", 4: \"B-PERSON\", 5: \"I-PERSON\",\n",
    "    6: \"B-NORP\", 7: \"B-GPE\", 8: \"I-GPE\", 9: \"B-LAW\", 10: \"I-LAW\", 11: \"B-ORG\", 12: \"I-ORG\",\n",
    "    13: \"B-PERCENT\", 14: \"I-PERCENT\", 15: \"B-ORDINAL\", 16: \"B-MONEY\", 17: \"I-MONEY\",\n",
    "    18: \"B-WORK_OF_ART\", 19: \"I-WORK_OF_ART\", 20: \"B-FAC\", 21: \"B-TIME\", 22: \"I-CARDINAL\",\n",
    "    23: \"B-LOC\", 24: \"B-QUANTITY\", 25: \"I-QUANTITY\", 26: \"I-NORP\", 27: \"I-LOC\",\n",
    "    28: \"B-PRODUCT\", 29: \"I-TIME\", 30: \"B-EVENT\", 31: \"I-EVENT\", 32: \"I-FAC\",\n",
    "    33: \"B-LANGUAGE\", 34: \"I-PRODUCT\", 35: \"I-ORDINAL\", 36: \"I-LANGUAGE\"\n",
    "}\n",
    "\n",
    "conll_label_to_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3,\n",
    "                     'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "id2label = {v: k for k, v in conll_label_to_id.items()}\n",
    "\n",
    "ontonotes_to_conll_entity = {\n",
    "    \"PERSON\": \"PER\", \"ORG\": \"ORG\", \"GPE\": \"LOC\", \"LOC\": \"LOC\",\n",
    "    \"NORP\": \"MISC\", \"FAC\": \"MISC\", \"EVENT\": \"MISC\", \"WORK_OF_ART\": \"MISC\",\n",
    "    \"LAW\": \"MISC\", \"PRODUCT\": \"MISC\", \"LANGUAGE\": \"MISC\",\n",
    "    \"DATE\": None, \"TIME\": None, \"PERCENT\": None, \"MONEY\": None,\n",
    "    \"QUANTITY\": None, \"ORDINAL\": None, \"CARDINAL\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40659f38-7b60-4393-addc-ff9117eaae6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.497815Z",
     "iopub.status.busy": "2025-06-14T15:00:59.497544Z",
     "iopub.status.idle": "2025-06-14T15:00:59.504736Z",
     "shell.execute_reply": "2025-06-14T15:00:59.504292Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data_list):\n",
    "\n",
    "    def process_single(data):\n",
    "        word_ids = data['word_ids']\n",
    "        predictions = data['predictions']\n",
    "        gold = data['gold']\n",
    "        tokenized_tokens = data['tokens']\n",
    "\n",
    "        word_ids = [a for a in word_ids if a is not None]\n",
    "\n",
    "        processed_predictions = []\n",
    "        processed_gold = []\n",
    "\n",
    "        current_word_id = None\n",
    "        current_predictions = []\n",
    "        current_gold = []\n",
    "\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id != current_word_id:\n",
    "                if current_predictions:\n",
    "                    processed_predictions.append(\n",
    "                        Counter(current_predictions).most_common(1)[0][0])\n",
    "                    processed_gold.append(\n",
    "                        Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "                current_word_id = word_id\n",
    "                current_predictions = [predictions[idx]]\n",
    "                current_gold = [gold[idx]]\n",
    "            else:\n",
    "                current_predictions.append(predictions[idx])\n",
    "                current_gold.append(gold[idx])\n",
    "\n",
    "        if current_predictions:\n",
    "            processed_predictions.append(\n",
    "                Counter(current_predictions).most_common(1)[0][0])\n",
    "            processed_gold.append(\n",
    "                Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "        return processed_predictions, processed_gold\n",
    "\n",
    "    processed_predictions_list = []\n",
    "    processed_gold_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        processed_predictions, processed_gold = process_single(data)\n",
    "        processed_predictions_list.append(processed_predictions)\n",
    "        processed_gold_list.append(processed_gold)\n",
    "\n",
    "    return processed_predictions_list, processed_gold_list\n",
    "\n",
    "\n",
    "def evaluate_predictions(p, test_data):\n",
    "    predictions, labels, _ = p\n",
    "\n",
    "    pred_indices = [np.argmax(p, axis=-1) for p in predictions]\n",
    "    label_indices = labels\n",
    "\n",
    "    pred_tags = [[id2label[p] for p, l in zip(p_seq, l_seq) if l != -100]\n",
    "                 for p_seq, l_seq in zip(pred_indices, label_indices)]\n",
    "    gold_tags = [[id2label[l] for l in l_seq if l != -100]\n",
    "                 for l_seq in label_indices]\n",
    "\n",
    "    def add_preds(example, idx):\n",
    "        length = len(example['word_ids'])\n",
    "        example['predictions'] = pred_tags[idx][:length]\n",
    "        example['gold'] = gold_tags[idx][:length]\n",
    "        return example\n",
    "\n",
    "    test_data = test_data.map(add_preds, with_indices=True)\n",
    "\n",
    "    length = len(test_data['predictions'][0])\n",
    "\n",
    "    pred, gold = process_data(test_data)\n",
    "\n",
    "    flat_pred = [label for seq in pred for label in seq]\n",
    "    flat_gold = [label for seq in gold for label in seq]\n",
    "\n",
    "    print(classification_report(flat_gold, flat_pred, zero_division=0))\n",
    "\n",
    "    return (flat_pred, flat_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aaa92f-8ae3-4b54-97e9-8ecd4ceae0a8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3daecd-13ac-46f9-8714-d1b09add4691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.506483Z",
     "iopub.status.busy": "2025-06-14T15:00:59.506130Z",
     "iopub.status.idle": "2025-06-14T15:00:59.913886Z",
     "shell.execute_reply": "2025-06-14T15:00:59.913290Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG',\n",
    "              'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    all_word_ids = []\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        all_word_ids.append(word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    tokenized_inputs[\"word_ids\"] = all_word_ids\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c54715b-4936-44d7-8bbb-8de8b99c9e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.916057Z",
     "iopub.status.busy": "2025-06-14T15:00:59.915817Z",
     "iopub.status.idle": "2025-06-14T15:00:59.947278Z",
     "shell.execute_reply": "2025-06-14T15:00:59.946769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = conll_main.map(tokenize_and_align_labels, batched=True)\n",
    "ontonotes_main = ontonotes_main.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13cc9c-62d8-4590-b3fb-38717515a142",
   "metadata": {},
   "source": [
    "# Deciding params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb9124a-b0d6-42ac-afad-52f9613636fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.949502Z",
     "iopub.status.busy": "2025-06-14T15:00:59.949242Z",
     "iopub.status.idle": "2025-06-14T15:00:59.951768Z",
     "shell.execute_reply": "2025-06-14T15:00:59.951393Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = ontonotes_main\n",
    "test_data = conll_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec15c6cf-0e39-4fdf-a1ca-70ea53bd60fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.953362Z",
     "iopub.status.busy": "2025-06-14T15:00:59.953005Z",
     "iopub.status.idle": "2025-06-14T15:00:59.955438Z",
     "shell.execute_reply": "2025-06-14T15:00:59.955056Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_name = 'onto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f947eb63-cced-4ef6-a353-f421fb46b50e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.957070Z",
     "iopub.status.busy": "2025-06-14T15:00:59.956696Z",
     "iopub.status.idle": "2025-06-14T15:01:03.019776Z",
     "shell.execute_reply": "2025-06-14T15:01:03.019207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/1248433719.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "mod = BertForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list))\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/{model_name}\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405da19b-d3b0-4392-8032-8ab1722685ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:03.022126Z",
     "iopub.status.busy": "2025-06-14T15:01:03.021851Z",
     "iopub.status.idle": "2025-06-14T16:13:55.574677Z",
     "shell.execute_reply": "2025-06-14T16:13:55.573903Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 1:12:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11508, training_loss=0.03779030413660462, metrics={'train_runtime': 4372.1353, 'train_samples_per_second': 42.111, 'train_steps_per_second': 2.632, 'total_flos': 1.853929724887653e+16, 'train_loss': 0.03779030413660462, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660e5e71-108a-45a7-932a-e4f2ccaf24ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:13:55.577330Z",
     "iopub.status.busy": "2025-06-14T16:13:55.577013Z",
     "iopub.status.idle": "2025-06-14T16:14:00.099920Z",
     "shell.execute_reply": "2025-06-14T16:14:00.099368Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(f\"./saved_model/{model_name}_{train_data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b3d9f3c-5c30-45fc-a8bb-1070b25adffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:14:00.102008Z",
     "iopub.status.busy": "2025-06-14T16:14:00.101728Z",
     "iopub.status.idle": "2025-06-14T16:16:06.909018Z",
     "shell.execute_reply": "2025-06-14T16:16:06.908359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af641f36-04e0-49dc-b04f-a93d415eb709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:06.911124Z",
     "iopub.status.busy": "2025-06-14T16:16:06.910891Z",
     "iopub.status.idle": "2025-06-14T16:16:07.698603Z",
     "shell.execute_reply": "2025-06-14T16:16:07.698028Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_results.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b84e338-e66a-4ca2-97a9-231acd097edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:07.700732Z",
     "iopub.status.busy": "2025-06-14T16:16:07.700463Z",
     "iopub.status.idle": "2025-06-14T16:16:33.919791Z",
     "shell.execute_reply": "2025-06-14T16:16:33.919192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   4%|▍         | 674/16595 [00:00<00:02, 6632.09 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   8%|▊         | 1401/16595 [00:00<00:05, 2972.69 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  12%|█▏        | 2000/16595 [00:00<00:04, 3278.14 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  16%|█▌        | 2649/16595 [00:00<00:03, 4065.54 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  22%|██▏       | 3572/16595 [00:00<00:03, 4096.20 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  26%|██▌       | 4245/16595 [00:01<00:03, 3127.88 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  29%|██▉       | 4862/16595 [00:01<00:03, 3653.65 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5345/16595 [00:01<00:04, 2538.06 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:04, 2578.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  41%|████      | 6782/16595 [00:02<00:02, 3384.54 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  44%|████▍     | 7351/16595 [00:02<00:02, 3474.78 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  48%|████▊     | 8000/16595 [00:02<00:03, 2168.24 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  53%|█████▎    | 8793/16595 [00:02<00:02, 2900.66 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  57%|█████▋    | 9424/16595 [00:03<00:03, 2004.74 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|██████    | 10000/16595 [00:03<00:02, 2376.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  63%|██████▎   | 10436/16595 [00:03<00:02, 2471.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▋   | 11000/16595 [00:03<00:01, 2859.29 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████▏  | 11829/16595 [00:03<00:01, 3813.33 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  75%|███████▌  | 12476/16595 [00:04<00:01, 3614.50 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  78%|███████▊  | 13000/16595 [00:04<00:01, 2690.31 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  81%|████████  | 13459/16595 [00:04<00:01, 2990.75 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  84%|████████▍ | 14000/16595 [00:04<00:01, 2264.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  90%|████████▉ | 14927/16595 [00:05<00:00, 3301.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  95%|█████████▌| 15806/16595 [00:05<00:00, 3844.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:05<00:00, 2013.23 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:06<00:00, 2751.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.80      0.80      8535\n",
      "      B-MISC       0.76      0.68      0.71      4062\n",
      "       B-ORG       0.75      0.50      0.60      7398\n",
      "       B-PER       0.86      0.93      0.89      7975\n",
      "       I-LOC       0.68      0.62      0.65      1356\n",
      "      I-MISC       0.53      0.58      0.56      1380\n",
      "       I-ORG       0.73      0.76      0.74      4251\n",
      "       I-PER       0.89      0.99      0.94      5503\n",
      "           O       0.98      0.99      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.76      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = evaluate_predictions(predictions, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605015e-fb9b-479c-9724-6528c607a87b",
   "metadata": {},
   "source": [
    "# Challenge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8682abd-dc85-40cd-b92f-236ae01437cc",
   "metadata": {},
   "source": [
    "## Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6104ffa6-882d-4e29-b96c-8450204c8949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:33.921882Z",
     "iopub.status.busy": "2025-06-14T16:16:33.921596Z",
     "iopub.status.idle": "2025-06-14T16:16:35.701106Z",
     "shell.execute_reply": "2025-06-14T16:16:35.700534Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"./Guided-Adversarial-Augmentation-main/Guided-Adversarial-Augmentation-main/data/data/conll2003/challenge_set.xlsx\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80bbab65-9121-40b6-9c4d-975672e74bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:35.703280Z",
     "iopub.status.busy": "2025-06-14T16:16:35.702999Z",
     "iopub.status.idle": "2025-06-14T16:16:36.063719Z",
     "shell.execute_reply": "2025-06-14T16:16:36.063191Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "i = 0\n",
    "while i < len(df):\n",
    "    row = df.iloc[i]\n",
    "    if str(row[0]).startswith(\"GUID\"):\n",
    "\n",
    "        guid = str(df.iloc[i][1]).strip()\n",
    "\n",
    "        try:\n",
    "            quality = int(str(df.iloc[i+1][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            quality = 999\n",
    "\n",
    "        try:\n",
    "            aug_type = int(str(df.iloc[i+2][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            aug_type = 999\n",
    "\n",
    "        tokens_row = df.iloc[i+3].dropna().tolist()[1:]\n",
    "        labels_row = df.iloc[i+4].dropna().tolist()[1:]\n",
    "        labels_row = [label.strip()\n",
    "                      for label in labels_row if label.strip() != \"\"]\n",
    "\n",
    "        if len(tokens_row) == len(labels_row):\n",
    "            examples.append({\n",
    "                \"guid\": guid,\n",
    "                \"quality\": quality,\n",
    "                \"aug_type\": aug_type,\n",
    "                \"tokens\": tokens_row,\n",
    "                \"labels\": labels_row\n",
    "            })\n",
    "\n",
    "        i += 6\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "challenge_dataset = Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8581fc-bacd-4793-8b65-ac9e826e4a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:36.065938Z",
     "iopub.status.busy": "2025-06-14T16:16:36.065655Z",
     "iopub.status.idle": "2025-06-14T16:16:36.068798Z",
     "shell.execute_reply": "2025-06-14T16:16:36.068408Z"
    }
   },
   "outputs": [],
   "source": [
    "conll_label_to_id = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1, 'I-PER': 2,\n",
    "    'B-ORG': 3, 'I-ORG': 4,\n",
    "    'B-LOC': 5, 'I-LOC': 6,\n",
    "    'B-MISC': 7, 'I-MISC': 8,\n",
    "}\n",
    "\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"labels\"] = [conll_label_to_id.get(\n",
    "        label, 0) for label in example[\"labels\"]]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc93860-6822-4475-ae3b-d8f588b84188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:36.070482Z",
     "iopub.status.busy": "2025-06-14T16:16:36.070091Z",
     "iopub.status.idle": "2025-06-14T16:16:36.203401Z",
     "shell.execute_reply": "2025-06-14T16:16:36.202921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  81%|████████  | 1148/1418 [00:00<00:00, 11395.03 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 11139.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "challenge_dataset = challenge_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f992fb-3c7e-435b-9789-ae8e11d7ce73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:36.205272Z",
     "iopub.status.busy": "2025-06-14T16:16:36.205009Z",
     "iopub.status.idle": "2025-06-14T16:16:36.774717Z",
     "shell.execute_reply": "2025-06-14T16:16:36.774240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████   | 1000/1418 [00:00<00:00, 2336.19 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 2652.09 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 2547.13 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stanford_encoded = challenge_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f993c5b-d7ab-4055-bad5-95b1eb325c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:36.776466Z",
     "iopub.status.busy": "2025-06-14T16:16:36.776223Z",
     "iopub.status.idle": "2025-06-14T16:16:49.726166Z",
     "shell.execute_reply": "2025-06-14T16:16:49.725667Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stanford_results = trainer.predict(stanford_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1306c0-7a1f-455d-b78f-5840f7bfde6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:49.727907Z",
     "iopub.status.busy": "2025-06-14T16:16:49.727674Z",
     "iopub.status.idle": "2025-06-14T16:16:49.787408Z",
     "shell.execute_reply": "2025-06-14T16:16:49.786817Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_stanford', 'wb') as f:\n",
    "    pickle.dump(stanford_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d20ae03-4fcb-4676-901b-a37fea28d79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:49.789657Z",
     "iopub.status.busy": "2025-06-14T16:16:49.789278Z",
     "iopub.status.idle": "2025-06-14T16:16:52.132588Z",
     "shell.execute_reply": "2025-06-14T16:16:52.132054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  46%|████▌     | 653/1418 [00:00<00:00, 6443.65 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 4599.46 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 4723.69 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.69      0.83      0.75       539\n",
      "      B-MISC       0.78      0.76      0.77       319\n",
      "       B-ORG       0.43      0.43      0.43      1214\n",
      "       B-PER       0.72      0.73      0.73      1067\n",
      "       I-LOC       0.57      0.72      0.64        79\n",
      "      I-MISC       0.53      0.70      0.60        82\n",
      "       I-ORG       0.72      0.94      0.81      2026\n",
      "       I-PER       0.90      0.70      0.79       939\n",
      "           O       0.99      0.96      0.97     22466\n",
      "\n",
      "    accuracy                           0.91     28731\n",
      "   macro avg       0.70      0.75      0.72     28731\n",
      "weighted avg       0.92      0.91      0.92     28731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = evaluate_predictions(stanford_results, stanford_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da7818-d0e5-4e71-9a16-178102b29167",
   "metadata": {},
   "source": [
    "## Personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11eb1b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:52.134494Z",
     "iopub.status.busy": "2025-06-14T16:16:52.134288Z",
     "iopub.status.idle": "2025-06-14T16:17:08.082155Z",
     "shell.execute_reply": "2025-06-14T16:17:08.081558Z"
    }
   },
   "outputs": [],
   "source": [
    "nd = NameDataset()\n",
    "country_codes = nd.get_country_codes()\n",
    "\n",
    "continent_names = {\n",
    "    'AF': 'Africa',\n",
    "    'NA': 'North America',\n",
    "    'OC': 'Oceania',\n",
    "    'AN': 'Antarctica',\n",
    "    'AS': 'Asia',\n",
    "    'EU': 'Europe',\n",
    "    'SA': 'South America',\n",
    "}\n",
    "\n",
    "continent_to_code = defaultdict(list)\n",
    "\n",
    "continent_to_countries = defaultdict(list)\n",
    "\n",
    "for code in country_codes:\n",
    "    try:\n",
    "        alpha_2 = code.alpha_2\n",
    "        country = pycountry.countries.get(alpha_2=alpha_2)\n",
    "        if not country:\n",
    "            continue\n",
    "\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha_2)\n",
    "        continent = continent_names[continent_code]\n",
    "\n",
    "        continent_to_code[continent].append(alpha_2)\n",
    "        continent_to_countries[continent].append((alpha_2, country.name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {code} due to error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7e40c24-e8b5-4227-b3eb-1b9d3f8fe084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:17:08.084447Z",
     "iopub.status.busy": "2025-06-14T16:17:08.084188Z",
     "iopub.status.idle": "2025-06-14T16:17:08.091822Z",
     "shell.execute_reply": "2025-06-14T16:17:08.091406Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_names(country, n=10):\n",
    "    names_dict = nd.get_top_names(n=n, country_alpha2=country)\n",
    "    names = []\n",
    "    if country in names_dict:\n",
    "        country_names = names_dict[country]\n",
    "        for gender in ['M', 'F']:\n",
    "            if gender in country_names:\n",
    "                names.extend(country_names[gender])\n",
    "    return list(set(names))\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tag_tokens(tokens, person_names):\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    for name in person_names:\n",
    "        name_tokens = name.split()\n",
    "        n_len = len(name_tokens)\n",
    "        for i in range(len(tokens) - n_len + 1):\n",
    "            if tokens[i:i + n_len] == name_tokens:\n",
    "                tags[i] = \"B-PER\"\n",
    "                for j in range(i + 1, i + n_len):\n",
    "                    tags[j] = \"I-PER\"\n",
    "    return tags\n",
    "\n",
    "\n",
    "def generate_challenge_dataset(num_samples=300):\n",
    "    dataset = []\n",
    "    failures = 0\n",
    "    max_failures = 1000\n",
    "\n",
    "    while len(dataset) < num_samples:\n",
    "        if failures >= max_failures:\n",
    "            print(f\"Stopped after {failures} failed attempts.\")\n",
    "            break\n",
    "\n",
    "        country = random.choice(chosen_countries)\n",
    "        names = get_names(country, n=10)\n",
    "\n",
    "        # Filter names: keep only those also in common_nouns\n",
    "        filtered_names = [\n",
    "            name for name in names if name.lower() in common_nouns]\n",
    "\n",
    "        if not filtered_names:\n",
    "            failures += 1\n",
    "            if failures % 10 == 0:\n",
    "                print(f\"{failures} failed attempts so far.\")\n",
    "            continue\n",
    "\n",
    "        # Pick one or two names as needed\n",
    "        if len(filtered_names) == 1:\n",
    "            name1 = filtered_names[0]\n",
    "            name2 = None\n",
    "        else:\n",
    "            name1, name2 = random.sample(filtered_names, 2)\n",
    "\n",
    "        template = random.choice(sentence_templates)\n",
    "\n",
    "        if \"{name2}\" in template and name2 is None:\n",
    "            sentence = template.format(name=name1, name2=name1)\n",
    "            person_names = [name1]\n",
    "        elif \"{name2}\" in template:\n",
    "            sentence = template.format(name=name1, name2=name2)\n",
    "            person_names = [name1, name2]\n",
    "        else:\n",
    "            sentence = template.format(name=name1)\n",
    "            person_names = [name1]\n",
    "\n",
    "        tokens = tokenize(sentence)\n",
    "        tags = tag_tokens(tokens, person_names)\n",
    "        dataset.append(list(zip(tokens, tags)))\n",
    "        print(len(dataset))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_to_csv(dataset, filepath=\"default_name.csv\"):\n",
    "    with open(filepath, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sentence_id\", \"token\", \"tag\"])\n",
    "        for idx, sentence in enumerate(dataset):\n",
    "            for token, tag in sentence:\n",
    "                writer.writerow([idx, token, tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba8822c-450b-4b4c-8c07-284e6bd814bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:17:08.093491Z",
     "iopub.status.busy": "2025-06-14T16:17:08.093215Z",
     "iopub.status.idle": "2025-06-14T16:17:08.097681Z",
     "shell.execute_reply": "2025-06-14T16:17:08.097278Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_csv(file,common=False):\n",
    "    print('evaluating', file)\n",
    "    scripted_challenge = pd.read_csv(file)\n",
    "\n",
    "    examples = []\n",
    "    for sentence_id, group in scripted_challenge.groupby(\"sentence_id\"):\n",
    "        tokens = group[\"token\"].tolist()\n",
    "        tags = group[\"tag\"].tolist()\n",
    "        examples.append({\"tokens\": tokens, \"ner_tags\": tags})\n",
    "\n",
    "    unique_tags = sorted(set(tag for ex in examples for tag in ex[\"ner_tags\"]))\n",
    "\n",
    "    for ex in examples:\n",
    "        ex[\"labels\"] = [conll_label_to_id[tag] for tag in ex[\"ner_tags\"]]\n",
    "\n",
    "    challenge_dataset = Dataset.from_list(examples)\n",
    "    tokenized = challenge_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "    a = trainer.predict(tokenized)\n",
    "\n",
    "    if common:\n",
    "        with open(f'./results/{model_name}_{train_data_name}_challenge_common.pkl', 'wb') as f:\n",
    "            pickle.dump(a, f)\n",
    "    else:\n",
    "        with open(f'./results/{model_name}_{train_data_name}_challenge_{file[:-3]}.pkl', 'wb') as f:\n",
    "            pickle.dump(a, f)\n",
    "\n",
    "    x, y = evaluate_predictions(a, tokenized)\n",
    "    print()\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "820fdce4-2e77-479b-b276-af5952269e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:17:08.099275Z",
     "iopub.status.busy": "2025-06-14T16:17:08.098984Z",
     "iopub.status.idle": "2025-06-14T16:18:00.282087Z",
     "shell.execute_reply": "2025-06-14T16:18:00.281498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating Asia_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7872.75 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7477.33 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8627.41 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8367.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.99      0.95      0.97      1134\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       0.46      1.00      0.63         6\n",
      "           O       1.00      0.98      0.99      9764\n",
      "\n",
      "    accuracy                           0.98     10904\n",
      "   macro avg       0.35      0.42      0.37     10904\n",
      "weighted avg       1.00      0.98      0.99     10904\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating South America_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7951.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7535.55 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8704.06 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8441.43 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.98      0.99      1164\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       1.00      1.00      1.00         2\n",
      "           O       1.00      0.98      0.99      9624\n",
      "\n",
      "    accuracy                           0.98     10790\n",
      "   macro avg       0.50      0.49      0.50     10790\n",
      "weighted avg       1.00      0.98      0.99     10790\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Africa_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7042.13 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6695.12 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8186.13 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7945.04 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.94      0.97      1163\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       1.00      1.00      1.00         9\n",
      "           O       1.00      0.98      0.99      9682\n",
      "\n",
      "    accuracy                           0.98     10854\n",
      "   macro avg       0.43      0.42      0.42     10854\n",
      "weighted avg       1.00      0.98      0.99     10854\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating North America_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7563.06 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7215.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8550.28 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8285.08 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.96      0.98      1145\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-ORG       0.00      0.00      0.00         0\n",
      "       I-PER       0.97      1.00      0.99        75\n",
      "           O       1.00      0.98      0.99      9569\n",
      "\n",
      "    accuracy                           0.98     10789\n",
      "   macro avg       0.37      0.37      0.37     10789\n",
      "weighted avg       1.00      0.98      0.99     10789\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Europe_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7392.20 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7016.51 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8444.07 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8205.82 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.97      0.98      1136\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "           O       1.00      0.98      0.99      9682\n",
      "\n",
      "    accuracy                           0.98     10818\n",
      "   macro avg       0.33      0.32      0.33     10818\n",
      "weighted avg       1.00      0.98      0.99     10818\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Oceania_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7729.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7349.89 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8592.61 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8325.55 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.87      0.93      1148\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "           O       1.00      0.98      0.99      9548\n",
      "\n",
      "    accuracy                           0.97     10696\n",
      "   macro avg       0.33      0.31      0.32     10696\n",
      "weighted avg       1.00      0.97      0.98     10696\n",
      "\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in list(continent_to_code.keys()):\n",
    "    evaluate_csv(x+'_ner_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb2fde83-63c8-4b9f-8e0d-d84901a1491f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:18:00.283996Z",
     "iopub.status.busy": "2025-06-14T16:18:00.283790Z",
     "iopub.status.idle": "2025-06-14T16:18:08.830894Z",
     "shell.execute_reply": "2025-06-14T16:18:08.830351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ./common_nouns_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8337.02 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7895.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8712.65 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8449.89 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.92      0.96      1168\n",
      "           O       1.00      1.00      1.00      9336\n",
      "\n",
      "    accuracy                           0.99     10504\n",
      "   macro avg       0.50      0.48      0.49     10504\n",
      "weighted avg       1.00      0.99      0.99     10504\n",
      "\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate_csv('./common_nouns_challenge.csv', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfabcf97-8d56-46d3-823f-6a0e4ca90c6c",
   "metadata": {},
   "source": [
    "# Seed Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a4dd316-8556-4f45-8bcc-03c5da965b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:18:08.833708Z",
     "iopub.status.busy": "2025-06-14T16:18:08.832551Z",
     "iopub.status.idle": "2025-06-14T20:50:50.959313Z",
     "shell.execute_reply": "2025-06-14T20:50:50.958558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 1:01:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   4%|▍         | 729/16595 [00:00<00:02, 7149.67 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1690/16595 [00:00<00:02, 5641.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2340/16595 [00:00<00:02, 4938.04 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4640.60 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3928/16595 [00:00<00:02, 5870.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4632/16595 [00:00<00:02, 5318.04 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5364/16595 [00:01<00:02, 4937.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4767.86 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6926/16595 [00:01<00:01, 5808.80 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7859/16595 [00:01<00:01, 5800.39 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  53%|█████▎    | 8878/16595 [00:01<00:01, 5829.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9901/16595 [00:01<00:01, 5921.34 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10893/16595 [00:01<00:00, 5942.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████▏  | 11865/16595 [00:02<00:00, 5916.32 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12781/16595 [00:02<00:00, 5762.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13713/16595 [00:02<00:00, 5502.87 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14485/16595 [00:02<00:00, 5411.20 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15442/16595 [00:02<00:00, 5642.70 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16451/16595 [00:02<00:00, 5772.12 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4483.32 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.80      0.79      8535\n",
      "      B-MISC       0.78      0.68      0.73      4062\n",
      "       B-ORG       0.74      0.51      0.60      7398\n",
      "       B-PER       0.92      0.92      0.92      7975\n",
      "       I-LOC       0.65      0.63      0.64      1356\n",
      "      I-MISC       0.55      0.56      0.55      1380\n",
      "       I-ORG       0.72      0.77      0.75      4251\n",
      "       I-PER       0.91      0.97      0.94      5503\n",
      "           O       0.98      0.99      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.76      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 58:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 761/16595 [00:00<00:02, 7477.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1693/16595 [00:00<00:02, 5728.70 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2339/16595 [00:00<00:02, 4980.81 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4662.03 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3911/16595 [00:00<00:02, 5845.99 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4639/16595 [00:00<00:02, 5310.43 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5369/16595 [00:01<00:02, 4947.97 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4755.37 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6941/16595 [00:01<00:01, 5834.07 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  46%|████▋     | 7709/16595 [00:01<00:01, 5496.65 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  51%|█████     | 8392/16595 [00:01<00:01, 5281.22 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▍    | 9000/16595 [00:01<00:01, 5112.77 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9888/16595 [00:01<00:01, 6012.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10882/16595 [00:01<00:00, 6013.57 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11869/16595 [00:02<00:00, 5966.09 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12756/16595 [00:02<00:00, 5705.66 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  80%|████████  | 13356/16595 [00:02<00:00, 5320.39 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  84%|████████▍ | 14000/16595 [00:02<00:00, 4993.56 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  90%|█████████ | 14966/16595 [00:02<00:00, 6027.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  96%|█████████▌| 15879/16595 [00:02<00:00, 5952.30 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 2704.78 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4547.16 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.80      0.80      8535\n",
      "      B-MISC       0.73      0.69      0.71      4062\n",
      "       B-ORG       0.74      0.51      0.60      7398\n",
      "       B-PER       0.88      0.92      0.90      7975\n",
      "       I-LOC       0.67      0.62      0.65      1356\n",
      "      I-MISC       0.55      0.57      0.56      1380\n",
      "       I-ORG       0.72      0.76      0.74      4251\n",
      "       I-PER       0.90      0.98      0.94      5503\n",
      "           O       0.98      0.99      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.76      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 50:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 758/16595 [00:00<00:02, 7433.70 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1687/16595 [00:00<00:02, 5639.33 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2334/16595 [00:00<00:02, 4949.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4626.52 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  23%|██▎       | 3896/16595 [00:00<00:02, 5773.05 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4636/16595 [00:00<00:02, 5270.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5371/16595 [00:01<00:02, 4891.74 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4719.27 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 7000/16595 [00:01<00:01, 5244.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7838/16595 [00:01<00:01, 5948.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  53%|█████▎    | 8876/16595 [00:01<00:01, 5941.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9912/16595 [00:01<00:01, 5997.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10877/16595 [00:01<00:00, 5963.59 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████▏  | 11860/16595 [00:02<00:00, 5923.46 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12777/16595 [00:02<00:00, 5739.30 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13716/16595 [00:02<00:00, 5502.79 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14482/16595 [00:02<00:00, 5344.27 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15440/16595 [00:02<00:00, 5519.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  96%|█████████▋| 16000/16595 [00:02<00:00, 5291.04 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 2827.37 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4724.78 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.79      0.80      0.80      8535\n",
      "      B-MISC       0.72      0.69      0.71      4062\n",
      "       B-ORG       0.77      0.51      0.62      7398\n",
      "       B-PER       0.90      0.92      0.91      7975\n",
      "       I-LOC       0.67      0.61      0.64      1356\n",
      "      I-MISC       0.52      0.57      0.54      1380\n",
      "       I-ORG       0.73      0.77      0.75      4251\n",
      "       I-PER       0.91      0.98      0.94      5503\n",
      "           O       0.98      0.99      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.76      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 49:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 765/16595 [00:00<00:02, 7521.22 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1679/16595 [00:00<00:02, 5652.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2339/16595 [00:00<00:02, 4886.54 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4575.55 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3918/16595 [00:00<00:02, 5784.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4633/16595 [00:00<00:02, 5235.86 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5365/16595 [00:01<00:02, 4876.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4724.27 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6903/16595 [00:01<00:01, 5715.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7854/16595 [00:01<00:01, 5762.71 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  53%|█████▎    | 8867/16595 [00:01<00:01, 5783.89 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9907/16595 [00:01<00:01, 5884.12 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10889/16595 [00:01<00:00, 5925.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████▏  | 11863/16595 [00:02<00:00, 5898.33 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12783/16595 [00:02<00:00, 5690.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13711/16595 [00:02<00:00, 5475.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14485/16595 [00:02<00:00, 5341.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15404/16595 [00:02<00:00, 5508.14 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  96%|█████████▋| 16000/16595 [00:02<00:00, 5323.69 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 2735.87 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4587.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.79      0.80      8535\n",
      "      B-MISC       0.79      0.68      0.73      4062\n",
      "       B-ORG       0.73      0.54      0.62      7398\n",
      "       B-PER       0.91      0.90      0.91      7975\n",
      "       I-LOC       0.64      0.62      0.63      1356\n",
      "      I-MISC       0.57      0.56      0.57      1380\n",
      "       I-ORG       0.72      0.75      0.73      4251\n",
      "       I-PER       0.90      0.97      0.93      5503\n",
      "           O       0.98      0.99      0.98    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.75      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051105/ipykernel_1402821/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 44:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.058600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 777/16595 [00:00<00:02, 7645.78 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1690/16595 [00:00<00:02, 5734.37 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2344/16595 [00:00<00:02, 4983.22 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4679.38 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3916/16595 [00:00<00:02, 5878.38 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4637/16595 [00:00<00:02, 5337.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5369/16595 [00:01<00:02, 4971.11 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4768.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6910/16595 [00:01<00:01, 5774.77 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7852/16595 [00:01<00:01, 5774.20 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  53%|█████▎    | 8866/16595 [00:01<00:01, 5782.32 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9881/16595 [00:01<00:01, 5742.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10895/16595 [00:01<00:00, 5837.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11867/16595 [00:02<00:00, 5841.34 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12781/16595 [00:02<00:00, 5673.75 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  80%|████████  | 13357/16595 [00:02<00:00, 5289.64 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  84%|████████▍ | 14000/16595 [00:02<00:00, 4967.39 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  90%|█████████ | 14967/16595 [00:02<00:00, 5979.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  96%|█████████▌| 15884/16595 [00:02<00:00, 5942.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 2739.34 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4587.36 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.80      0.81      8535\n",
      "      B-MISC       0.80      0.67      0.73      4062\n",
      "       B-ORG       0.76      0.52      0.62      7398\n",
      "       B-PER       0.91      0.91      0.91      7975\n",
      "       I-LOC       0.65      0.63      0.64      1356\n",
      "      I-MISC       0.53      0.56      0.54      1380\n",
      "       I-ORG       0.71      0.78      0.74      4251\n",
      "       I-PER       0.91      0.97      0.94      5503\n",
      "           O       0.98      0.99      0.98    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.78      0.76      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [33, 42, 57, 106, 812, ]\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(conll_label_to_id)\n",
    "    )\n",
    "\n",
    "    seed_args = TrainingArguments(\n",
    "        output_dir=f\"./output/{seed}\",\n",
    "        seed=seed,\n",
    "        eval_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "        logging_steps=1000,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    seed_trainer = Trainer(\n",
    "        model=seed_model,\n",
    "        args=seed_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    seed_trainer.train()\n",
    "\n",
    "    pred = seed_trainer.predict(test_data)\n",
    "\n",
    "    x, y = evaluate_predictions(pred, test_data)\n",
    "    eval_result = {'predictions': x, 'seed': seed}\n",
    "    results.append(eval_result)\n",
    "    with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9a317a-7bc8-4283-80e2-dc82360cbe9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:50:50.962093Z",
     "iopub.status.busy": "2025-06-14T20:50:50.961678Z",
     "iopub.status.idle": "2025-06-14T20:50:51.170025Z",
     "shell.execute_reply": "2025-06-14T20:50:51.169479Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'rb') as f:\n",
    "    seed_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c499fcf-70b1-46d4-b0b9-8217b0c17d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:50:51.172306Z",
     "iopub.status.busy": "2025-06-14T20:50:51.171907Z",
     "iopub.status.idle": "2025-06-14T20:50:55.829660Z",
     "shell.execute_reply": "2025-06-14T20:50:55.829170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 1: 0.952904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 2: 0.950803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 3: 0.951529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 4: 0.952004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 2: 0.951898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 3: 0.948910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 4: 0.946124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 2 and seed 3: 0.947940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 2 and seed 4: 0.948772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 3 and seed 4: 0.948406\n",
      "\n",
      "Average Cohen's kappa across all pairs: 0.949929\n"
     ]
    }
   ],
   "source": [
    "kappa_scores = []\n",
    "\n",
    "for i, j in combinations(range(len(seed_res)), 2):\n",
    "    preds_i = seed_res[i]['predictions']\n",
    "    preds_j = seed_res[j]['predictions']\n",
    "\n",
    "    kappa = cohen_kappa_score(preds_i, preds_j)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    print(f\"Cohen's kappa between seed {i} and seed {j}: {kappa:.6f}\")\n",
    "\n",
    "average_kappa = sum(kappa_scores) / len(kappa_scores)\n",
    "print(f\"\\nAverage Cohen's kappa across all pairs: {average_kappa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edf15a7d-d0a4-48fb-be53-2330aec4f100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:50:55.831580Z",
     "iopub.status.busy": "2025-06-14T20:50:55.831207Z",
     "iopub.status.idle": "2025-06-14T20:50:56.560825Z",
     "shell.execute_reply": "2025-06-14T20:50:56.560331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Krippendorff’s alpha (nominal): 0.9499\n"
     ]
    }
   ],
   "source": [
    "data = np.array([seed['predictions'] for seed in seed_res])\n",
    "\n",
    "alpha = krippendorff.alpha(reliability_data=data,\n",
    "                           level_of_measurement='nominal')\n",
    "\n",
    "print(f\"\\nKrippendorff’s alpha (nominal): {alpha:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
