{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d461041d-8606-408d-884c-f76b5a1ad8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:51:31.966114Z",
     "iopub.status.busy": "2025-05-28T10:51:31.965109Z",
     "iopub.status.idle": "2025-05-28T10:53:06.850059Z",
     "shell.execute_reply": "2025-05-28T10:53:06.849548Z",
     "shell.execute_reply.started": "2025-05-28T10:51:31.966114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Software\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3b8b29c-81ba-45cd-abe1-7ab9825a7f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T12:05:06.079281Z",
     "iopub.status.busy": "2025-05-28T12:05:06.079281Z",
     "iopub.status.idle": "2025-05-28T12:05:06.961369Z",
     "shell.execute_reply": "2025-05-28T12:05:06.960015Z",
     "shell.execute_reply.started": "2025-05-28T12:05:06.079281Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "conll_label_to_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3,\n",
    "                     'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "id2label = {v: k for k, v in conll_label_to_id.items()}\n",
    "\n",
    "conll_encoded = load_from_disk(\"./splits/conll_encoded\")\n",
    "conll_encoded = conll_encoded.select(range(1))\n",
    "ontonotes_encoded = load_from_disk(\"./splits/ontonotes_encoded\")\n",
    "ontonotes_encoded = ontonotes_encoded.select(range(1))\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        true_predictions.append(\n",
    "            [id2label[p] for p, l in zip(pred_seq, label_seq) if l != -100])\n",
    "        true_labels.append([id2label[l] for l in label_seq if l != -100])\n",
    "\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "115f0956-76fd-4d7d-aadc-4d8c024cb2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T12:05:06.961369Z",
     "iopub.status.busy": "2025-05-28T12:05:06.961369Z",
     "iopub.status.idle": "2025-05-28T12:05:12.582847Z",
     "shell.execute_reply": "2025-05-28T12:05:12.582340Z",
     "shell.execute_reply.started": "2025-05-28T12:05:06.961369Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\NIKHIL\\AppData\\Local\\Temp\\ipykernel_20168\\2915304987.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  conll_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Software\\Anaconda\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Software\\Anaconda\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "seeds = [42]\n",
    "# seeds = [42, 106, 812, 2025, 9999]\n",
    "results = []\n",
    "\n",
    "# with open('./results/seed_var_results.pkl', 'rb') as f:\n",
    "#     results = pickle.load(f)\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    conll_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(conll_label_to_id)\n",
    "    )\n",
    "\n",
    "    conll_args = TrainingArguments(\n",
    "        output_dir=f\"./results/conll_seed_{seed}\",\n",
    "        seed=seed,\n",
    "        eval_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "        logging_steps=1000,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    conll_trainer = Trainer(\n",
    "        model=conll_model,\n",
    "        args=conll_args,\n",
    "        train_dataset=conll_encoded,\n",
    "        eval_dataset=ontonotes_encoded,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    conll_trainer.train()\n",
    "    conll_trainer.save_model(\"./saved_model/conll_seed_\"+str(seed))\n",
    "\n",
    "    pred = conll_trainer.predict(ontonotes_encoded)\n",
    "    eval_result = {'predictions': pred, 'seed': seed}\n",
    "    results.append(eval_result)\n",
    "    with open('./results/seed_var_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39e210-7361-465a-9f1e-e76f1f795018",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-28T12:04:19.713823Z",
     "iopub.status.idle": "2025-05-28T12:04:19.714144Z",
     "shell.execute_reply": "2025-05-28T12:04:19.714144Z",
     "shell.execute_reply.started": "2025-05-28T12:04:19.714144Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_trainer.predict(ontonotes_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90383d48-540c-4e0f-a648-beb1f7e2d0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
