{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c15dd3-5458-4883-9e72-a7ab6ff1db94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:30:01.672261Z",
     "iopub.status.busy": "2025-07-03T13:30:01.672261Z",
     "iopub.status.idle": "2025-07-03T13:31:45.025454Z",
     "shell.execute_reply": "2025-07-03T13:31:45.024446Z",
     "shell.execute_reply.started": "2025-07-03T13:30:01.672261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Software\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from nameparser import HumanName\n",
    "from names_dataset import NameDataset, NameWrapper\n",
    "from ethnicseer import EthnicClassifier\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pycountry_convert as pc\n",
    "import pycountry\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, cohen_kappa_score\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from datasets import ClassLabel\n",
    "from evaluate import load as load_metric\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecc9f10-5de7-4101-b978-d5a8c0cccdba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.029467Z",
     "iopub.status.busy": "2025-07-03T13:31:45.028466Z",
     "iopub.status.idle": "2025-07-03T13:31:45.036998Z",
     "shell.execute_reply": "2025-07-03T13:31:45.034988Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.029467Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503ac47c-b69d-47fd-bd74-30b26ba97c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.041004Z",
     "iopub.status.busy": "2025-07-03T13:31:45.039001Z",
     "iopub.status.idle": "2025-07-03T13:31:45.758801Z",
     "shell.execute_reply": "2025-07-03T13:31:45.757790Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.041004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = load_from_disk(\"./splits/conll_main\")\n",
    "conll_clean = load_from_disk(\"./splits/conll_clean\")\n",
    "\n",
    "ontonotes_main = load_from_disk(\"./splits/ontonotes_main\")\n",
    "ontonotes_clean = load_from_disk(\"./splits/ontonotes_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b08f4ae-7b2d-448a-8217-dbc8acb0e845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:25:35.682152Z",
     "iopub.status.busy": "2025-07-03T12:25:35.681148Z",
     "iopub.status.idle": "2025-07-03T12:25:36.302724Z",
     "shell.execute_reply": "2025-07-03T12:25:36.300701Z",
     "shell.execute_reply.started": "2025-07-03T12:25:35.682152Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "flat_conll = list(chain.from_iterable(conll_main['tokens']))\n",
    "flat_onto = list(chain.from_iterable(ontonotes_main['tokens']))\n",
    "flat_conll_clean = list(chain.from_iterable(conll_clean['tokens']))\n",
    "flat_onto_clean = list(chain.from_iterable(ontonotes_clean['tokens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5369020-ce17-44a1-b634-25d6e770ccfe",
   "metadata": {},
   "source": [
    "# Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd834e98-1132-4ea7-ab80-12501a446f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.762048Z",
     "iopub.status.busy": "2025-07-03T13:31:45.761048Z",
     "iopub.status.idle": "2025-07-03T13:31:45.851664Z",
     "shell.execute_reply": "2025-07-03T13:31:45.849653Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.761048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661b808-b12c-4bd9-9e89-606cf2b1e4f7",
   "metadata": {},
   "source": [
    "# Tokenisation & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831cedee-f0f0-4c67-b225-4b6af76759b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.855671Z",
     "iopub.status.busy": "2025-07-03T13:31:45.854666Z",
     "iopub.status.idle": "2025-07-03T13:31:45.867943Z",
     "shell.execute_reply": "2025-07-03T13:31:45.866927Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.855671Z"
    }
   },
   "outputs": [],
   "source": [
    "ontonotes_id_to_label = {\n",
    "    0: \"O\", 1: \"B-CARDINAL\", 2: \"B-DATE\", 3: \"I-DATE\", 4: \"B-PERSON\", 5: \"I-PERSON\",\n",
    "    6: \"B-NORP\", 7: \"B-GPE\", 8: \"I-GPE\", 9: \"B-LAW\", 10: \"I-LAW\", 11: \"B-ORG\", 12: \"I-ORG\",\n",
    "    13: \"B-PERCENT\", 14: \"I-PERCENT\", 15: \"B-ORDINAL\", 16: \"B-MONEY\", 17: \"I-MONEY\",\n",
    "    18: \"B-WORK_OF_ART\", 19: \"I-WORK_OF_ART\", 20: \"B-FAC\", 21: \"B-TIME\", 22: \"I-CARDINAL\",\n",
    "    23: \"B-LOC\", 24: \"B-QUANTITY\", 25: \"I-QUANTITY\", 26: \"I-NORP\", 27: \"I-LOC\",\n",
    "    28: \"B-PRODUCT\", 29: \"I-TIME\", 30: \"B-EVENT\", 31: \"I-EVENT\", 32: \"I-FAC\",\n",
    "    33: \"B-LANGUAGE\", 34: \"I-PRODUCT\", 35: \"I-ORDINAL\", 36: \"I-LANGUAGE\"\n",
    "}\n",
    "\n",
    "conll_label_to_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3,\n",
    "                     'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "id2label = {v: k for k, v in conll_label_to_id.items()}\n",
    "\n",
    "ontonotes_to_conll_entity = {\n",
    "    \"PERSON\": \"PER\", \"ORG\": \"ORG\", \"GPE\": \"LOC\", \"LOC\": \"LOC\",\n",
    "    \"NORP\": \"MISC\", \"FAC\": \"MISC\", \"EVENT\": \"MISC\", \"WORK_OF_ART\": \"MISC\",\n",
    "    \"LAW\": \"MISC\", \"PRODUCT\": \"MISC\", \"LANGUAGE\": \"MISC\",\n",
    "    \"DATE\": None, \"TIME\": None, \"PERCENT\": None, \"MONEY\": None,\n",
    "    \"QUANTITY\": None, \"ORDINAL\": None, \"CARDINAL\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d151cb53-9464-4c7e-aa46-a65b0e7d5fcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.871940Z",
     "iopub.status.busy": "2025-07-03T13:31:45.870943Z",
     "iopub.status.idle": "2025-07-03T13:31:45.891444Z",
     "shell.execute_reply": "2025-07-03T13:31:45.889432Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.871940Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data_list):\n",
    "\n",
    "    def process_single(data):\n",
    "        word_ids = data['word_ids']\n",
    "        predictions = data['predictions']\n",
    "        gold = data['gold']\n",
    "        tokenized_tokens = data['tokens']\n",
    "\n",
    "        word_ids = [a for a in word_ids if a is not None]\n",
    "\n",
    "        processed_predictions = []\n",
    "        processed_gold = []\n",
    "\n",
    "        current_word_id = None\n",
    "        current_predictions = []\n",
    "        current_gold = []\n",
    "\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id != current_word_id:\n",
    "                if current_predictions:\n",
    "                    processed_predictions.append(\n",
    "                        Counter(current_predictions).most_common(1)[0][0])\n",
    "                    processed_gold.append(\n",
    "                        Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "                current_word_id = word_id\n",
    "                current_predictions = [predictions[idx]]\n",
    "                current_gold = [gold[idx]]\n",
    "            else:\n",
    "                current_predictions.append(predictions[idx])\n",
    "                current_gold.append(gold[idx])\n",
    "\n",
    "        if current_predictions:\n",
    "            processed_predictions.append(\n",
    "                Counter(current_predictions).most_common(1)[0][0])\n",
    "            processed_gold.append(\n",
    "                Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "        return processed_predictions, processed_gold\n",
    "\n",
    "    processed_predictions_list = []\n",
    "    processed_gold_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        processed_predictions, processed_gold = process_single(data)\n",
    "        processed_predictions_list.append(processed_predictions)\n",
    "        processed_gold_list.append(processed_gold)\n",
    "\n",
    "    return processed_predictions_list, processed_gold_list\n",
    "\n",
    "\n",
    "def evaluate_predictions(p, test_data):\n",
    "    predictions, labels, _ = p\n",
    "\n",
    "    pred_indices = [np.argmax(p, axis=-1) for p in predictions]\n",
    "    label_indices = labels\n",
    "\n",
    "    pred_tags = [[id2label[p] for p, l in zip(p_seq, l_seq) if l != -100]\n",
    "                 for p_seq, l_seq in zip(pred_indices, label_indices)]\n",
    "    gold_tags = [[id2label[l] for l in l_seq if l != -100]\n",
    "                 for l_seq in label_indices]\n",
    "\n",
    "    def add_preds(example, idx):\n",
    "        length = len(example['word_ids'])\n",
    "        example['predictions'] = pred_tags[idx][:length]\n",
    "        example['gold'] = gold_tags[idx][:length]\n",
    "        return example\n",
    "\n",
    "    test_data = test_data.map(add_preds, with_indices=True)\n",
    "\n",
    "    length = len(test_data['predictions'][0])\n",
    "\n",
    "    pred, gold = process_data(test_data)\n",
    "\n",
    "    flat_pred = [label for seq in pred for label in seq]\n",
    "    flat_gold = [label for seq in gold for label in seq]\n",
    "\n",
    "    print(classification_report(flat_gold, flat_pred, zero_division=0))\n",
    "\n",
    "    return (flat_pred, flat_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3daecd-13ac-46f9-8714-d1b09add4691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:45.894448Z",
     "iopub.status.busy": "2025-07-03T13:31:45.894448Z",
     "iopub.status.idle": "2025-07-03T13:31:46.391859Z",
     "shell.execute_reply": "2025-07-03T13:31:46.390851Z",
     "shell.execute_reply.started": "2025-07-03T13:31:45.894448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG',\n",
    "              'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    all_word_ids = []\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        all_word_ids.append(word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    tokenized_inputs[\"word_ids\"] = all_word_ids\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c54715b-4936-44d7-8bbb-8de8b99c9e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:31:46.393865Z",
     "iopub.status.busy": "2025-07-03T13:31:46.393865Z",
     "iopub.status.idle": "2025-07-03T13:32:31.471261Z",
     "shell.execute_reply": "2025-07-03T13:32:31.470253Z",
     "shell.execute_reply.started": "2025-07-03T13:31:46.393865Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d4c1d36b2340358ce5e8092891463b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5bf5ce130c4daf8d45340621558c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4284bef4a742f79d33c29603b5c8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809db7a3edf4a4eb5085e468b055e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conll_main = conll_main.map(tokenize_and_align_labels, batched=True)\n",
    "conll_clean = conll_clean.map(tokenize_and_align_labels, batched=True)\n",
    "ontonotes_main = ontonotes_main.map(tokenize_and_align_labels, batched=True)\n",
    "ontonotes_clean = ontonotes_clean.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4231967-66a6-40a3-82ad-6be8ff04fcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:45:21.594417Z",
     "iopub.status.busy": "2025-07-03T13:45:21.594417Z",
     "iopub.status.idle": "2025-07-03T13:45:21.603271Z",
     "shell.execute_reply": "2025-07-03T13:45:21.601754Z",
     "shell.execute_reply.started": "2025-07-03T13:45:21.594417Z"
    }
   },
   "outputs": [],
   "source": [
    "def caps_correct(flat_tokens, x, y):\n",
    "    assert len(flat_tokens) == len(x) == len(y)\n",
    "\n",
    "    correct_caps = 0\n",
    "    incorrect_caps = 0\n",
    "\n",
    "    for token, pred, gold in zip(flat_tokens, x, y):\n",
    "        if token and token[0].isupper():\n",
    "            if pred == gold:\n",
    "                correct_caps += 1\n",
    "            else:\n",
    "                print(token)\n",
    "                incorrect_caps += 1\n",
    "\n",
    "    print(f\"Capitalized Tokens - Correct Predictions: {correct_caps}\")\n",
    "    print(f\"Capitalized Tokens - Incorrect Predictions: {incorrect_caps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146a939-18e4-449b-822e-bd0eb1c93be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:46:21.329969Z",
     "iopub.status.busy": "2025-07-03T13:46:21.328970Z",
     "iopub.status.idle": "2025-07-03T13:46:21.922417Z",
     "shell.execute_reply": "2025-07-03T13:46:21.921900Z",
     "shell.execute_reply.started": "2025-07-03T13:46:21.329969Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b6d1e-49a5-419c-8320-8e3ce35ee85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:24:18.064055Z",
     "iopub.status.busy": "2025-07-03T12:24:18.063066Z",
     "iopub.status.idle": "2025-07-03T12:25:04.335173Z",
     "shell.execute_reply": "2025-07-03T12:25:04.334162Z",
     "shell.execute_reply.started": "2025-07-03T12:24:18.064055Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = ontonotes_main\n",
    "test_data = conll_main\n",
    "\n",
    "train_data_name = 'onto'\n",
    "\n",
    "model_path = f\"./saved_model/{model_name}_{train_data_name}\"\n",
    "mod = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/random\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "x, y = evaluate_predictions(predictions, test_data)\n",
    "\n",
    "caps_correct(flat_conll, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08676971-9cdd-40ae-b790-8304c8054b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:24:18.064055Z",
     "iopub.status.busy": "2025-07-03T12:24:18.063066Z",
     "iopub.status.idle": "2025-07-03T12:25:04.335173Z",
     "shell.execute_reply": "2025-07-03T12:25:04.334162Z",
     "shell.execute_reply.started": "2025-07-03T12:24:18.064055Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = conll_main\n",
    "test_data = ontonotes_main\n",
    "\n",
    "train_data_name = 'conll'\n",
    "\n",
    "model_path = f\"./saved_model/{model_name}_{train_data_name}\"\n",
    "mod = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/random\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "x, y = evaluate_predictions(predictions, test_data)\n",
    "\n",
    "caps_correct(flat_onto, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537449c4-9fd3-481c-9fe0-ac9aba5e1365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:24:18.064055Z",
     "iopub.status.busy": "2025-07-03T12:24:18.063066Z",
     "iopub.status.idle": "2025-07-03T12:25:04.335173Z",
     "shell.execute_reply": "2025-07-03T12:25:04.334162Z",
     "shell.execute_reply.started": "2025-07-03T12:24:18.064055Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = conll_main\n",
    "test_data = conll_clean\n",
    "\n",
    "train_data_name = 'conll'\n",
    "\n",
    "model_path = f\"./saved_model/{model_name}_{train_data_name}\"\n",
    "mod = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/random\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "x, y = evaluate_predictions(predictions, test_data)\n",
    "\n",
    "caps_correct(flat_conll_clean, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559f97e-a334-435f-91b0-d1cf5058f694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:24:18.064055Z",
     "iopub.status.busy": "2025-07-03T12:24:18.063066Z",
     "iopub.status.idle": "2025-07-03T12:25:04.335173Z",
     "shell.execute_reply": "2025-07-03T12:25:04.334162Z",
     "shell.execute_reply.started": "2025-07-03T12:24:18.064055Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = ontonotes_main\n",
    "test_data = ontonotes_clean\n",
    "\n",
    "train_data_name = 'onto'\n",
    "\n",
    "model_path = f\"./saved_model/{model_name}_{train_data_name}\"\n",
    "mod = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/random\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "x, y = evaluate_predictions(predictions, test_data)\n",
    "\n",
    "caps_correct(flat_onto_clean, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b6befaf-80b1-4ed9-a8f9-9e3d5f032f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T14:13:54.469436Z",
     "iopub.status.busy": "2025-07-03T14:13:54.468418Z",
     "iopub.status.idle": "2025-07-03T14:13:54.482075Z",
     "shell.execute_reply": "2025-07-03T14:13:54.479057Z",
     "shell.execute_reply.started": "2025-07-03T14:13:54.469436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18384442782348542 ontoconll\n",
      "0.12173006843541118 conllonto\n",
      "0.03754316361766218 conllconll\n",
      "0.036979235550853064 ontonto\n"
     ]
    }
   ],
   "source": [
    "print(9832/(43648+9832), 'ontoconll')\n",
    "\n",
    "print(18339/(132314+18339), 'conllonto')\n",
    "\n",
    "print(511/(13100+511), 'conllconll')\n",
    "\n",
    "print(1398/(36407+1398), 'ontonto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b7135-106d-4eb2-b40c-b732724bcb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
