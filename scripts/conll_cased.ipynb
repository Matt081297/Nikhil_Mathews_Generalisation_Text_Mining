{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a840269-1836-4e2f-b68f-cf051f8fb4bc",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T20:46:11.930312Z",
     "iopub.status.busy": "2025-06-13T20:46:11.929804Z",
     "iopub.status.idle": "2025-06-13T20:47:28.996253Z",
     "shell.execute_reply": "2025-06-13T20:47:28.994235Z",
     "shell.execute_reply.started": "2025-06-13T20:46:11.930312Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Software\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from nameparser import HumanName\n",
    "from names_dataset import NameDataset, NameWrapper\n",
    "from ethnicseer import EthnicClassifier\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pycountry_convert as pc\n",
    "import pycountry\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, cohen_kappa_score\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from datasets import ClassLabel\n",
    "from evaluate import load as load_metric\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7573e05-e012-4aad-8cc8-cf1059f36e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aad505-c3e4-4097-9cbb-a52fd4904934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = load_from_disk(\"./splits/conll_main\")\n",
    "\n",
    "ontonotes_main = load_from_disk(\"./splits/ontonotes_main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c4f89-dbd0-41cf-94ea-65816c3250ca",
   "metadata": {},
   "source": [
    "# Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28293a63-0d2c-4656-9288-8872aa08c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b951be-37ac-4db8-bcc5-945356c8bc33",
   "metadata": {},
   "source": [
    "# Tokenisation & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41793608-572c-473b-b770-1cda88a2f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontonotes_id_to_label = {\n",
    "    0: \"O\", 1: \"B-CARDINAL\", 2: \"B-DATE\", 3: \"I-DATE\", 4: \"B-PERSON\", 5: \"I-PERSON\",\n",
    "    6: \"B-NORP\", 7: \"B-GPE\", 8: \"I-GPE\", 9: \"B-LAW\", 10: \"I-LAW\", 11: \"B-ORG\", 12: \"I-ORG\",\n",
    "    13: \"B-PERCENT\", 14: \"I-PERCENT\", 15: \"B-ORDINAL\", 16: \"B-MONEY\", 17: \"I-MONEY\",\n",
    "    18: \"B-WORK_OF_ART\", 19: \"I-WORK_OF_ART\", 20: \"B-FAC\", 21: \"B-TIME\", 22: \"I-CARDINAL\",\n",
    "    23: \"B-LOC\", 24: \"B-QUANTITY\", 25: \"I-QUANTITY\", 26: \"I-NORP\", 27: \"I-LOC\",\n",
    "    28: \"B-PRODUCT\", 29: \"I-TIME\", 30: \"B-EVENT\", 31: \"I-EVENT\", 32: \"I-FAC\",\n",
    "    33: \"B-LANGUAGE\", 34: \"I-PRODUCT\", 35: \"I-ORDINAL\", 36: \"I-LANGUAGE\"\n",
    "}\n",
    "\n",
    "conll_label_to_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3,\n",
    "                     'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "id2label = {v: k for k, v in conll_label_to_id.items()}\n",
    "\n",
    "ontonotes_to_conll_entity = {\n",
    "    \"PERSON\": \"PER\", \"ORG\": \"ORG\", \"GPE\": \"LOC\", \"LOC\": \"LOC\",\n",
    "    \"NORP\": \"MISC\", \"FAC\": \"MISC\", \"EVENT\": \"MISC\", \"WORK_OF_ART\": \"MISC\",\n",
    "    \"LAW\": \"MISC\", \"PRODUCT\": \"MISC\", \"LANGUAGE\": \"MISC\",\n",
    "    \"DATE\": None, \"TIME\": None, \"PERCENT\": None, \"MONEY\": None,\n",
    "    \"QUANTITY\": None, \"ORDINAL\": None, \"CARDINAL\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40659f38-7b60-4393-addc-ff9117eaae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_list):\n",
    "\n",
    "    def process_single(data):\n",
    "        word_ids = data['word_ids']\n",
    "        predictions = data['predictions']\n",
    "        gold = data['gold']\n",
    "        tokenized_tokens = data['tokens']\n",
    "\n",
    "        word_ids = [a for a in word_ids if a is not None]\n",
    "\n",
    "        processed_predictions = []\n",
    "        processed_gold = []\n",
    "\n",
    "        current_word_id = None\n",
    "        current_predictions = []\n",
    "        current_gold = []\n",
    "\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id != current_word_id:\n",
    "                if current_predictions:\n",
    "                    processed_predictions.append(\n",
    "                        Counter(current_predictions).most_common(1)[0][0])\n",
    "                    processed_gold.append(\n",
    "                        Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "                current_word_id = word_id\n",
    "                current_predictions = [predictions[idx]]\n",
    "                current_gold = [gold[idx]]\n",
    "            else:\n",
    "                current_predictions.append(predictions[idx])\n",
    "                current_gold.append(gold[idx])\n",
    "\n",
    "        if current_predictions:\n",
    "            processed_predictions.append(\n",
    "                Counter(current_predictions).most_common(1)[0][0])\n",
    "            processed_gold.append(\n",
    "                Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "        return processed_predictions, processed_gold\n",
    "\n",
    "    processed_predictions_list = []\n",
    "    processed_gold_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        processed_predictions, processed_gold = process_single(data)\n",
    "        processed_predictions_list.append(processed_predictions)\n",
    "        processed_gold_list.append(processed_gold)\n",
    "\n",
    "    return processed_predictions_list, processed_gold_list\n",
    "\n",
    "\n",
    "def evaluate_predictions(p, test_data):\n",
    "    predictions, labels, _ = p\n",
    "\n",
    "    pred_indices = [np.argmax(p, axis=-1) for p in predictions]\n",
    "    label_indices = labels\n",
    "\n",
    "    pred_tags = [[id2label[p] for p, l in zip(p_seq, l_seq) if l != -100]\n",
    "                 for p_seq, l_seq in zip(pred_indices, label_indices)]\n",
    "    gold_tags = [[id2label[l] for l in l_seq if l != -100]\n",
    "                 for l_seq in label_indices]\n",
    "\n",
    "    def add_preds(example, idx):\n",
    "        length = len(example['word_ids'])\n",
    "        example['predictions'] = pred_tags[idx][:length]\n",
    "        example['gold'] = gold_tags[idx][:length]\n",
    "        return example\n",
    "\n",
    "    test_data = test_data.map(add_preds, with_indices=True)\n",
    "\n",
    "    length = len(test_data['predictions'][0])\n",
    "\n",
    "    pred, gold = process_data(test_data)\n",
    "\n",
    "    flat_pred = [label for seq in pred for label in seq]\n",
    "    flat_gold = [label for seq in gold for label in seq]\n",
    "\n",
    "    print(classification_report(flat_gold, flat_pred, zero_division=0))\n",
    "\n",
    "    return (flat_pred, flat_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aaa92f-8ae3-4b54-97e9-8ecd4ceae0a8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3daecd-13ac-46f9-8714-d1b09add4691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG',\n",
    "              'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    all_word_ids = []\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        all_word_ids.append(word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    tokenized_inputs[\"word_ids\"] = all_word_ids\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54715b-4936-44d7-8bbb-8de8b99c9e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = conll_main.map(tokenize_and_align_labels, batched=True)\n",
    "ontonotes_main = ontonotes_main.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13cc9c-62d8-4590-b3fb-38717515a142",
   "metadata": {},
   "source": [
    "# Deciding params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d57ca-49d4-4048-81f1-e97ef29500db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = conll_main\n",
    "test_data = ontonotes_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad3561-02df-4042-9919-1c0469568e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_name = 'conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947eb63-cced-4ef6-a353-f421fb46b50e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = BertForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list))\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/{model_name}\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405da19b-d3b0-4392-8032-8ab1722685ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e5e71-108a-45a7-932a-e4f2ccaf24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f\"./saved_model/{model_name}_{train_data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d9f3c-5c30-45fc-a8bb-1070b25adffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af641f36-04e0-49dc-b04f-a93d415eb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_results.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84e338-e66a-4ca2-97a9-231acd097edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = evaluate_predictions(predictions, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605015e-fb9b-479c-9724-6528c607a87b",
   "metadata": {},
   "source": [
    "# Challenge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8682abd-dc85-40cd-b92f-236ae01437cc",
   "metadata": {},
   "source": [
    "## Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104ffa6-882d-4e29-b96c-8450204c8949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"./Guided-Adversarial-Augmentation-main/Guided-Adversarial-Augmentation-main/data/data/conll2003/challenge_set.xlsx\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbab65-9121-40b6-9c4d-975672e74bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "i = 0\n",
    "while i < len(df):\n",
    "    row = df.iloc[i]\n",
    "    if str(row[0]).startswith(\"GUID\"):\n",
    "\n",
    "        guid = str(df.iloc[i][1]).strip()\n",
    "\n",
    "        try:\n",
    "            quality = int(str(df.iloc[i+1][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            quality = 999\n",
    "\n",
    "        try:\n",
    "            aug_type = int(str(df.iloc[i+2][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            aug_type = 999\n",
    "\n",
    "        tokens_row = df.iloc[i+3].dropna().tolist()[1:]\n",
    "        labels_row = df.iloc[i+4].dropna().tolist()[1:]\n",
    "        labels_row = [label.strip()\n",
    "                      for label in labels_row if label.strip() != \"\"]\n",
    "\n",
    "        if len(tokens_row) == len(labels_row):\n",
    "            examples.append({\n",
    "                \"guid\": guid,\n",
    "                \"quality\": quality,\n",
    "                \"aug_type\": aug_type,\n",
    "                \"tokens\": tokens_row,\n",
    "                \"labels\": labels_row\n",
    "            })\n",
    "\n",
    "        i += 6\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "challenge_dataset = Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8581fc-bacd-4793-8b65-ac9e826e4a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:23:04.271486Z",
     "iopub.status.busy": "2025-06-13T21:23:04.271486Z",
     "iopub.status.idle": "2025-06-13T21:23:04.280634Z",
     "shell.execute_reply": "2025-06-13T21:23:04.278474Z",
     "shell.execute_reply.started": "2025-06-13T21:23:04.271486Z"
    }
   },
   "outputs": [],
   "source": [
    "conll_label_to_id = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1, 'I-PER': 2,\n",
    "    'B-ORG': 3, 'I-ORG': 4,\n",
    "    'B-LOC': 5, 'I-LOC': 6,\n",
    "    'B-MISC': 7, 'I-MISC': 8,\n",
    "}\n",
    "\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"labels\"] = [conll_label_to_id.get(\n",
    "        label, 0) for label in example[\"labels\"]]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc93860-6822-4475-ae3b-d8f588b84188",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_dataset = challenge_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f992fb-3c7e-435b-9789-ae8e11d7ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_encoded = challenge_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f993c5b-d7ab-4055-bad5-95b1eb325c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stanford_results = CBC_trainer.predict(stanford_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1306c0-7a1f-455d-b78f-5840f7bfde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_stanford', 'wb') as f:\n",
    "    pickle.dump(stanford_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20ae03-4fcb-4676-901b-a37fea28d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = evaluate_predictions(stanford_results, stanford_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da7818-d0e5-4e71-9a16-178102b29167",
   "metadata": {},
   "source": [
    "## Personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e40c24-e8b5-4227-b3eb-1b9d3f8fe084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:06:02.935411Z",
     "iopub.status.busy": "2025-06-13T21:06:02.934413Z",
     "iopub.status.idle": "2025-06-13T21:06:02.956545Z",
     "shell.execute_reply": "2025-06-13T21:06:02.954527Z",
     "shell.execute_reply.started": "2025-06-13T21:06:02.935411Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_names(country, n=10):\n",
    "    names_dict = nd.get_top_names(n=n, country_alpha2=country)\n",
    "    names = []\n",
    "    if country in names_dict:\n",
    "        country_names = names_dict[country]\n",
    "        for gender in ['M', 'F']:\n",
    "            if gender in country_names:\n",
    "                names.extend(country_names[gender])\n",
    "    return list(set(names))\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tag_tokens(tokens, person_names):\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    for name in person_names:\n",
    "        name_tokens = name.split()\n",
    "        n_len = len(name_tokens)\n",
    "        for i in range(len(tokens) - n_len + 1):\n",
    "            if tokens[i:i + n_len] == name_tokens:\n",
    "                tags[i] = \"B-PER\"\n",
    "                for j in range(i + 1, i + n_len):\n",
    "                    tags[j] = \"I-PER\"\n",
    "    return tags\n",
    "\n",
    "\n",
    "def generate_challenge_dataset(num_samples=300):\n",
    "    dataset = []\n",
    "    failures = 0\n",
    "    max_failures = 1000\n",
    "\n",
    "    while len(dataset) < num_samples:\n",
    "        if failures >= max_failures:\n",
    "            print(f\"Stopped after {failures} failed attempts.\")\n",
    "            break\n",
    "\n",
    "        country = random.choice(chosen_countries)\n",
    "        names = get_names(country, n=10)\n",
    "\n",
    "        # Filter names: keep only those also in common_nouns\n",
    "        filtered_names = [\n",
    "            name for name in names if name.lower() in common_nouns]\n",
    "\n",
    "        if not filtered_names:\n",
    "            failures += 1\n",
    "            if failures % 10 == 0:\n",
    "                print(f\"{failures} failed attempts so far.\")\n",
    "            continue\n",
    "\n",
    "        # Pick one or two names as needed\n",
    "        if len(filtered_names) == 1:\n",
    "            name1 = filtered_names[0]\n",
    "            name2 = None\n",
    "        else:\n",
    "            name1, name2 = random.sample(filtered_names, 2)\n",
    "\n",
    "        template = random.choice(sentence_templates)\n",
    "\n",
    "        if \"{name2}\" in template and name2 is None:\n",
    "            sentence = template.format(name=name1, name2=name1)\n",
    "            person_names = [name1]\n",
    "        elif \"{name2}\" in template:\n",
    "            sentence = template.format(name=name1, name2=name2)\n",
    "            person_names = [name1, name2]\n",
    "        else:\n",
    "            sentence = template.format(name=name1)\n",
    "            person_names = [name1]\n",
    "\n",
    "        tokens = tokenize(sentence)\n",
    "        tags = tag_tokens(tokens, person_names)\n",
    "        dataset.append(list(zip(tokens, tags)))\n",
    "        print(len(dataset))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_to_csv(dataset, filepath=\"default_name.csv\"):\n",
    "    with open(filepath, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sentence_id\", \"token\", \"tag\"])\n",
    "        for idx, sentence in enumerate(dataset):\n",
    "            for token, tag in sentence:\n",
    "                writer.writerow([idx, token, tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba8822c-450b-4b4c-8c07-284e6bd814bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T21:22:39.475563Z",
     "iopub.status.busy": "2025-06-13T21:22:39.475563Z",
     "iopub.status.idle": "2025-06-13T21:22:39.488076Z",
     "shell.execute_reply": "2025-06-13T21:22:39.486068Z",
     "shell.execute_reply.started": "2025-06-13T21:22:39.475563Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_csv(file):\n",
    "    print('evaluating', file)\n",
    "    scripted_challenge = pd.read_csv(file)\n",
    "\n",
    "    examples = []\n",
    "    for sentence_id, group in scripted_challenge.groupby(\"sentence_id\"):\n",
    "        tokens = group[\"token\"].tolist()\n",
    "        tags = group[\"tag\"].tolist()\n",
    "        examples.append({\"tokens\": tokens, \"ner_tags\": tags})\n",
    "\n",
    "    unique_tags = sorted(set(tag for ex in examples for tag in ex[\"ner_tags\"]))\n",
    "\n",
    "    for ex in examples:\n",
    "        ex[\"labels\"] = [conll_label_to_id[tag] for tag in ex[\"ner_tags\"]]\n",
    "\n",
    "    challenge_dataset = Dataset.from_list(examples)\n",
    "    tokenized = challenge_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "    a = trainer.predict(tokenized)\n",
    "\n",
    "    with open(f'./results/{model_name}_{train_data_name}_challenge_{file[:-3]}.pkl', 'wb') as f:\n",
    "        pickle.dump(a, f)\n",
    "\n",
    "    x, y = evaluate_predictions(a, tokenized)\n",
    "    print()\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fdce4-2e77-479b-b276-af5952269e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(continent_to_code.keys()):\n",
    "    evaluate_csv(x+'_ner_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2fde83-63c8-4b9f-8e0d-d84901a1491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_csv('./common_nouns_challenge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfabcf97-8d56-46d3-823f-6a0e4ca90c6c",
   "metadata": {},
   "source": [
    "# Seed Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dd316-8556-4f45-8bcc-03c5da965b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seeds = [33, 42, 57, 106, 812, ]\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(conll_label_to_id)\n",
    "    )\n",
    "\n",
    "    seed_args = TrainingArguments(\n",
    "        output_dir=f\"./output/{seed}\",\n",
    "        seed=seed,\n",
    "        eval_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "        logging_steps=1000,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    seed_trainer = Trainer(\n",
    "        model=seed_model,\n",
    "        args=seed_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    seed_trainer.train()\n",
    "\n",
    "    pred = seed_trainer.predict(test_data)\n",
    "\n",
    "    x, y = evaluate_predictions(pred, test_data)\n",
    "    eval_result = {'predictions': x, 'seed': seed}\n",
    "    results.append(eval_result)\n",
    "    with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a317a-7bc8-4283-80e2-dc82360cbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'rb') as f:\n",
    "    seed_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c499fcf-70b1-46d4-b0b9-8217b0c17d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scores = []\n",
    "\n",
    "for i, j in combinations(range(len(seed_res)), 2):\n",
    "    preds_i = seed_res[i]['predictions']\n",
    "    preds_j = seed_res[j]['predictions']\n",
    "\n",
    "    kappa = cohen_kappa_score(preds_i, preds_j)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    print(f\"Cohen's kappa between seed {i} and seed {j}: {kappa:.6f}\")\n",
    "\n",
    "average_kappa = sum(kappa_scores) / len(kappa_scores)\n",
    "print(f\"\\nAverage Cohen's kappa across all pairs: {average_kappa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf15a7d-d0a4-48fb-be53-2330aec4f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([seed['predictions'] for seed in seed_res])\n",
    "\n",
    "alpha = krippendorff.alpha(reliability_data=data,\n",
    "                           level_of_measurement='nominal')\n",
    "\n",
    "print(f\"\\nKrippendorffâ€™s alpha (nominal): {alpha:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
