{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a840269-1836-4e2f-b68f-cf051f8fb4bc",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T14:59:20.081117Z",
     "iopub.status.busy": "2025-06-14T14:59:20.080755Z",
     "iopub.status.idle": "2025-06-14T15:00:59.704128Z",
     "shell.execute_reply": "2025-06-14T15:00:59.703512Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from nameparser import HumanName\n",
    "from names_dataset import NameDataset, NameWrapper\n",
    "from ethnicseer import EthnicClassifier\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pycountry_convert as pc\n",
    "import pycountry\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, cohen_kappa_score\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from datasets import ClassLabel\n",
    "from evaluate import load as load_metric\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7573e05-e012-4aad-8cc8-cf1059f36e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.706873Z",
     "iopub.status.busy": "2025-06-14T15:00:59.706194Z",
     "iopub.status.idle": "2025-06-14T15:00:59.709642Z",
     "shell.execute_reply": "2025-06-14T15:00:59.709244Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9aad505-c3e4-4097-9cbb-a52fd4904934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.711288Z",
     "iopub.status.busy": "2025-06-14T15:00:59.710966Z",
     "iopub.status.idle": "2025-06-14T15:00:59.800242Z",
     "shell.execute_reply": "2025-06-14T15:00:59.799848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = load_from_disk(\"./splits/conll_main\")\n",
    "\n",
    "ontonotes_main = load_from_disk(\"./splits/ontonotes_main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c4f89-dbd0-41cf-94ea-65816c3250ca",
   "metadata": {},
   "source": [
    "# Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28293a63-0d2c-4656-9288-8872aa08c838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.801954Z",
     "iopub.status.busy": "2025-06-14T15:00:59.801664Z",
     "iopub.status.idle": "2025-06-14T15:00:59.857136Z",
     "shell.execute_reply": "2025-06-14T15:00:59.856675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b951be-37ac-4db8-bcc5-945356c8bc33",
   "metadata": {},
   "source": [
    "# Tokenisation & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41793608-572c-473b-b770-1cda88a2f950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.858846Z",
     "iopub.status.busy": "2025-06-14T15:00:59.858623Z",
     "iopub.status.idle": "2025-06-14T15:00:59.862879Z",
     "shell.execute_reply": "2025-06-14T15:00:59.862456Z"
    }
   },
   "outputs": [],
   "source": [
    "ontonotes_id_to_label = {\n",
    "    0: \"O\", 1: \"B-CARDINAL\", 2: \"B-DATE\", 3: \"I-DATE\", 4: \"B-PERSON\", 5: \"I-PERSON\",\n",
    "    6: \"B-NORP\", 7: \"B-GPE\", 8: \"I-GPE\", 9: \"B-LAW\", 10: \"I-LAW\", 11: \"B-ORG\", 12: \"I-ORG\",\n",
    "    13: \"B-PERCENT\", 14: \"I-PERCENT\", 15: \"B-ORDINAL\", 16: \"B-MONEY\", 17: \"I-MONEY\",\n",
    "    18: \"B-WORK_OF_ART\", 19: \"I-WORK_OF_ART\", 20: \"B-FAC\", 21: \"B-TIME\", 22: \"I-CARDINAL\",\n",
    "    23: \"B-LOC\", 24: \"B-QUANTITY\", 25: \"I-QUANTITY\", 26: \"I-NORP\", 27: \"I-LOC\",\n",
    "    28: \"B-PRODUCT\", 29: \"I-TIME\", 30: \"B-EVENT\", 31: \"I-EVENT\", 32: \"I-FAC\",\n",
    "    33: \"B-LANGUAGE\", 34: \"I-PRODUCT\", 35: \"I-ORDINAL\", 36: \"I-LANGUAGE\"\n",
    "}\n",
    "\n",
    "conll_label_to_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3,\n",
    "                     'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "id2label = {v: k for k, v in conll_label_to_id.items()}\n",
    "\n",
    "ontonotes_to_conll_entity = {\n",
    "    \"PERSON\": \"PER\", \"ORG\": \"ORG\", \"GPE\": \"LOC\", \"LOC\": \"LOC\",\n",
    "    \"NORP\": \"MISC\", \"FAC\": \"MISC\", \"EVENT\": \"MISC\", \"WORK_OF_ART\": \"MISC\",\n",
    "    \"LAW\": \"MISC\", \"PRODUCT\": \"MISC\", \"LANGUAGE\": \"MISC\",\n",
    "    \"DATE\": None, \"TIME\": None, \"PERCENT\": None, \"MONEY\": None,\n",
    "    \"QUANTITY\": None, \"ORDINAL\": None, \"CARDINAL\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40659f38-7b60-4393-addc-ff9117eaae6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.864445Z",
     "iopub.status.busy": "2025-06-14T15:00:59.864170Z",
     "iopub.status.idle": "2025-06-14T15:00:59.871285Z",
     "shell.execute_reply": "2025-06-14T15:00:59.870903Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data_list):\n",
    "\n",
    "    def process_single(data):\n",
    "        word_ids = data['word_ids']\n",
    "        predictions = data['predictions']\n",
    "        gold = data['gold']\n",
    "        tokenized_tokens = data['tokens']\n",
    "\n",
    "        word_ids = [a for a in word_ids if a is not None]\n",
    "\n",
    "        processed_predictions = []\n",
    "        processed_gold = []\n",
    "\n",
    "        current_word_id = None\n",
    "        current_predictions = []\n",
    "        current_gold = []\n",
    "\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id != current_word_id:\n",
    "                if current_predictions:\n",
    "                    processed_predictions.append(\n",
    "                        Counter(current_predictions).most_common(1)[0][0])\n",
    "                    processed_gold.append(\n",
    "                        Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "                current_word_id = word_id\n",
    "                current_predictions = [predictions[idx]]\n",
    "                current_gold = [gold[idx]]\n",
    "            else:\n",
    "                current_predictions.append(predictions[idx])\n",
    "                current_gold.append(gold[idx])\n",
    "\n",
    "        if current_predictions:\n",
    "            processed_predictions.append(\n",
    "                Counter(current_predictions).most_common(1)[0][0])\n",
    "            processed_gold.append(\n",
    "                Counter(current_gold).most_common(1)[0][0])\n",
    "\n",
    "        return processed_predictions, processed_gold\n",
    "\n",
    "    processed_predictions_list = []\n",
    "    processed_gold_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        processed_predictions, processed_gold = process_single(data)\n",
    "        processed_predictions_list.append(processed_predictions)\n",
    "        processed_gold_list.append(processed_gold)\n",
    "\n",
    "    return processed_predictions_list, processed_gold_list\n",
    "\n",
    "\n",
    "def evaluate_predictions(p, test_data):\n",
    "    predictions, labels, _ = p\n",
    "\n",
    "    pred_indices = [np.argmax(p, axis=-1) for p in predictions]\n",
    "    label_indices = labels\n",
    "\n",
    "    pred_tags = [[id2label[p] for p, l in zip(p_seq, l_seq) if l != -100]\n",
    "                 for p_seq, l_seq in zip(pred_indices, label_indices)]\n",
    "    gold_tags = [[id2label[l] for l in l_seq if l != -100]\n",
    "                 for l_seq in label_indices]\n",
    "\n",
    "    def add_preds(example, idx):\n",
    "        length = len(example['word_ids'])\n",
    "        example['predictions'] = pred_tags[idx][:length]\n",
    "        example['gold'] = gold_tags[idx][:length]\n",
    "        return example\n",
    "\n",
    "    test_data = test_data.map(add_preds, with_indices=True)\n",
    "\n",
    "    length = len(test_data['predictions'][0])\n",
    "\n",
    "    pred, gold = process_data(test_data)\n",
    "\n",
    "    flat_pred = [label for seq in pred for label in seq]\n",
    "    flat_gold = [label for seq in gold for label in seq]\n",
    "\n",
    "    print(classification_report(flat_gold, flat_pred, zero_division=0))\n",
    "\n",
    "    return (flat_pred, flat_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aaa92f-8ae3-4b54-97e9-8ecd4ceae0a8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3daecd-13ac-46f9-8714-d1b09add4691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:00:59.872826Z",
     "iopub.status.busy": "2025-06-14T15:00:59.872690Z",
     "iopub.status.idle": "2025-06-14T15:01:00.364408Z",
     "shell.execute_reply": "2025-06-14T15:01:00.363821Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG',\n",
    "              'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    all_word_ids = []\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        all_word_ids.append(word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    tokenized_inputs[\"word_ids\"] = all_word_ids\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c54715b-4936-44d7-8bbb-8de8b99c9e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:00.366964Z",
     "iopub.status.busy": "2025-06-14T15:01:00.366637Z",
     "iopub.status.idle": "2025-06-14T15:01:00.401462Z",
     "shell.execute_reply": "2025-06-14T15:01:00.400987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conll_main = conll_main.map(tokenize_and_align_labels, batched=True)\n",
    "ontonotes_main = ontonotes_main.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13cc9c-62d8-4590-b3fb-38717515a142",
   "metadata": {},
   "source": [
    "# Deciding params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb9124a-b0d6-42ac-afad-52f9613636fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:00.403572Z",
     "iopub.status.busy": "2025-06-14T15:01:00.403242Z",
     "iopub.status.idle": "2025-06-14T15:01:00.405958Z",
     "shell.execute_reply": "2025-06-14T15:01:00.405585Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = ontonotes_main\n",
    "test_data = conll_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec15c6cf-0e39-4fdf-a1ca-70ea53bd60fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:00.407474Z",
     "iopub.status.busy": "2025-06-14T15:01:00.407256Z",
     "iopub.status.idle": "2025-06-14T15:01:00.409852Z",
     "shell.execute_reply": "2025-06-14T15:01:00.409456Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_name = 'onto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f947eb63-cced-4ef6-a353-f421fb46b50e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:00.411498Z",
     "iopub.status.busy": "2025-06-14T15:01:00.411126Z",
     "iopub.status.idle": "2025-06-14T15:01:03.012868Z",
     "shell.execute_reply": "2025-06-14T15:01:03.012267Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/1248433719.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "mod = BertForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list))\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./output/{model_name}\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mod,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405da19b-d3b0-4392-8032-8ab1722685ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:01:03.015398Z",
     "iopub.status.busy": "2025-06-14T15:01:03.015133Z",
     "iopub.status.idle": "2025-06-14T16:12:24.729121Z",
     "shell.execute_reply": "2025-06-14T16:12:24.728372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 1:11:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11508, training_loss=0.04673927795655992, metrics={'train_runtime': 4281.2673, 'train_samples_per_second': 43.004, 'train_steps_per_second': 2.688, 'total_flos': 1.7975130525033858e+16, 'train_loss': 0.04673927795655992, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660e5e71-108a-45a7-932a-e4f2ccaf24ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:12:24.732003Z",
     "iopub.status.busy": "2025-06-14T16:12:24.731514Z",
     "iopub.status.idle": "2025-06-14T16:12:27.877518Z",
     "shell.execute_reply": "2025-06-14T16:12:27.876956Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(f\"./saved_model/{model_name}_{train_data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b3d9f3c-5c30-45fc-a8bb-1070b25adffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:12:27.879827Z",
     "iopub.status.busy": "2025-06-14T16:12:27.879365Z",
     "iopub.status.idle": "2025-06-14T16:14:50.703663Z",
     "shell.execute_reply": "2025-06-14T16:14:50.702945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af641f36-04e0-49dc-b04f-a93d415eb709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:14:50.705899Z",
     "iopub.status.busy": "2025-06-14T16:14:50.705564Z",
     "iopub.status.idle": "2025-06-14T16:14:51.454894Z",
     "shell.execute_reply": "2025-06-14T16:14:51.454289Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_results.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b84e338-e66a-4ca2-97a9-231acd097edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:14:51.457361Z",
     "iopub.status.busy": "2025-06-14T16:14:51.456964Z",
     "iopub.status.idle": "2025-06-14T16:15:14.654607Z",
     "shell.execute_reply": "2025-06-14T16:15:14.654015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 779/16595 [00:00<00:02, 7665.83 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1677/16595 [00:00<00:02, 5475.46 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2315/16595 [00:00<00:03, 4678.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 2971/16595 [00:00<00:02, 5219.52 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3901/16595 [00:00<00:02, 5246.62 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4628/16595 [00:00<00:02, 4911.08 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5361/16595 [00:01<00:02, 4591.36 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4485.77 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6915/16595 [00:01<00:01, 5514.49 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7845/16595 [00:01<00:01, 5564.81 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  51%|█████     | 8440/16595 [00:01<00:01, 5310.67 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▍    | 9000/16595 [00:01<00:01, 5127.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  59%|█████▉    | 9865/16595 [00:01<00:01, 5977.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10887/16595 [00:02<00:00, 5910.44 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████▏  | 11843/16595 [00:02<00:00, 5772.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12760/16595 [00:02<00:00, 5569.60 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  80%|████████  | 13341/16595 [00:02<00:00, 5137.47 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  84%|████████▍ | 14000/16595 [00:02<00:00, 4813.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  90%|████████▉ | 14931/16595 [00:02<00:00, 5780.51 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  95%|█████████▌| 15826/16595 [00:02<00:00, 5698.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16454/16595 [00:03<00:00, 5405.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4736.49 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.79      0.90      0.84      8535\n",
      "      B-MISC       0.77      0.69      0.73      4062\n",
      "       B-ORG       0.73      0.52      0.61      7398\n",
      "       B-PER       0.92      0.93      0.93      7975\n",
      "       I-LOC       0.60      0.77      0.68      1356\n",
      "      I-MISC       0.42      0.69      0.52      1380\n",
      "       I-ORG       0.63      0.77      0.69      4251\n",
      "       I-PER       0.90      0.98      0.94      5503\n",
      "           O       0.99      0.98      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.75      0.80      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = evaluate_predictions(predictions, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605015e-fb9b-479c-9724-6528c607a87b",
   "metadata": {},
   "source": [
    "# Challenge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8682abd-dc85-40cd-b92f-236ae01437cc",
   "metadata": {},
   "source": [
    "## Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6104ffa6-882d-4e29-b96c-8450204c8949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:14.656707Z",
     "iopub.status.busy": "2025-06-14T16:15:14.656496Z",
     "iopub.status.idle": "2025-06-14T16:15:15.970960Z",
     "shell.execute_reply": "2025-06-14T16:15:15.970404Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"./Guided-Adversarial-Augmentation-main/Guided-Adversarial-Augmentation-main/data/data/conll2003/challenge_set.xlsx\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80bbab65-9121-40b6-9c4d-975672e74bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:15.973265Z",
     "iopub.status.busy": "2025-06-14T16:15:15.972956Z",
     "iopub.status.idle": "2025-06-14T16:15:16.774672Z",
     "shell.execute_reply": "2025-06-14T16:15:16.774150Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "i = 0\n",
    "while i < len(df):\n",
    "    row = df.iloc[i]\n",
    "    if str(row[0]).startswith(\"GUID\"):\n",
    "\n",
    "        guid = str(df.iloc[i][1]).strip()\n",
    "\n",
    "        try:\n",
    "            quality = int(str(df.iloc[i+1][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            quality = 999\n",
    "\n",
    "        try:\n",
    "            aug_type = int(str(df.iloc[i+2][1]).strip())\n",
    "        except (ValueError, TypeError):\n",
    "            aug_type = 999\n",
    "\n",
    "        tokens_row = df.iloc[i+3].dropna().tolist()[1:]\n",
    "        labels_row = df.iloc[i+4].dropna().tolist()[1:]\n",
    "        labels_row = [label.strip()\n",
    "                      for label in labels_row if label.strip() != \"\"]\n",
    "\n",
    "        if len(tokens_row) == len(labels_row):\n",
    "            examples.append({\n",
    "                \"guid\": guid,\n",
    "                \"quality\": quality,\n",
    "                \"aug_type\": aug_type,\n",
    "                \"tokens\": tokens_row,\n",
    "                \"labels\": labels_row\n",
    "            })\n",
    "\n",
    "        i += 6\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "challenge_dataset = Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8581fc-bacd-4793-8b65-ac9e826e4a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:16.776898Z",
     "iopub.status.busy": "2025-06-14T16:15:16.776601Z",
     "iopub.status.idle": "2025-06-14T16:15:16.779753Z",
     "shell.execute_reply": "2025-06-14T16:15:16.779355Z"
    }
   },
   "outputs": [],
   "source": [
    "conll_label_to_id = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1, 'I-PER': 2,\n",
    "    'B-ORG': 3, 'I-ORG': 4,\n",
    "    'B-LOC': 5, 'I-LOC': 6,\n",
    "    'B-MISC': 7, 'I-MISC': 8,\n",
    "}\n",
    "\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"labels\"] = [conll_label_to_id.get(\n",
    "        label, 0) for label in example[\"labels\"]]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc93860-6822-4475-ae3b-d8f588b84188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:16.781350Z",
     "iopub.status.busy": "2025-06-14T16:15:16.781090Z",
     "iopub.status.idle": "2025-06-14T16:15:16.912533Z",
     "shell.execute_reply": "2025-06-14T16:15:16.912002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 1178/1418 [00:00<00:00, 11679.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 11308.73 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "challenge_dataset = challenge_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f992fb-3c7e-435b-9789-ae8e11d7ce73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:16.914285Z",
     "iopub.status.busy": "2025-06-14T16:15:16.914043Z",
     "iopub.status.idle": "2025-06-14T16:15:17.467788Z",
     "shell.execute_reply": "2025-06-14T16:15:17.467325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  71%|███████   | 1000/1418 [00:00<00:00, 2435.52 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 2716.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 2620.36 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stanford_encoded = challenge_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f993c5b-d7ab-4055-bad5-95b1eb325c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:17.469621Z",
     "iopub.status.busy": "2025-06-14T16:15:17.469326Z",
     "iopub.status.idle": "2025-06-14T16:15:29.223940Z",
     "shell.execute_reply": "2025-06-14T16:15:29.223422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stanford_results = trainer.predict(stanford_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1306c0-7a1f-455d-b78f-5840f7bfde6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:29.225883Z",
     "iopub.status.busy": "2025-06-14T16:15:29.225477Z",
     "iopub.status.idle": "2025-06-14T16:15:29.288539Z",
     "shell.execute_reply": "2025-06-14T16:15:29.287921Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_stanford', 'wb') as f:\n",
    "    pickle.dump(stanford_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d20ae03-4fcb-4676-901b-a37fea28d79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:29.290672Z",
     "iopub.status.busy": "2025-06-14T16:15:29.290432Z",
     "iopub.status.idle": "2025-06-14T16:15:31.511549Z",
     "shell.execute_reply": "2025-06-14T16:15:31.510996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  48%|████▊     | 677/1418 [00:00<00:00, 6683.92 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 4660.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1418/1418 [00:00<00:00, 4812.38 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.56      0.82      0.67       539\n",
      "      B-MISC       0.77      0.75      0.76       319\n",
      "       B-ORG       0.40      0.42      0.41      1214\n",
      "       B-PER       0.80      0.66      0.72      1067\n",
      "       I-LOC       0.53      0.77      0.63        79\n",
      "      I-MISC       0.48      0.73      0.58        82\n",
      "       I-ORG       0.67      0.88      0.76      2026\n",
      "       I-PER       0.94      0.66      0.78       939\n",
      "           O       0.98      0.96      0.97     22466\n",
      "\n",
      "    accuracy                           0.90     28731\n",
      "   macro avg       0.68      0.74      0.70     28731\n",
      "weighted avg       0.92      0.90      0.91     28731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = evaluate_predictions(stanford_results, stanford_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da7818-d0e5-4e71-9a16-178102b29167",
   "metadata": {},
   "source": [
    "## Personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "405cc2a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:31.513534Z",
     "iopub.status.busy": "2025-06-14T16:15:31.513242Z",
     "iopub.status.idle": "2025-06-14T16:15:47.679186Z",
     "shell.execute_reply": "2025-06-14T16:15:47.678593Z"
    }
   },
   "outputs": [],
   "source": [
    "nd = NameDataset()\n",
    "country_codes = nd.get_country_codes()\n",
    "\n",
    "continent_names = {\n",
    "    'AF': 'Africa',\n",
    "    'NA': 'North America',\n",
    "    'OC': 'Oceania',\n",
    "    'AN': 'Antarctica',\n",
    "    'AS': 'Asia',\n",
    "    'EU': 'Europe',\n",
    "    'SA': 'South America',\n",
    "}\n",
    "\n",
    "continent_to_code = defaultdict(list)\n",
    "\n",
    "continent_to_countries = defaultdict(list)\n",
    "\n",
    "for code in country_codes:\n",
    "    try:\n",
    "        alpha_2 = code.alpha_2\n",
    "        country = pycountry.countries.get(alpha_2=alpha_2)\n",
    "        if not country:\n",
    "            continue\n",
    "\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha_2)\n",
    "        continent = continent_names[continent_code]\n",
    "\n",
    "        continent_to_code[continent].append(alpha_2)\n",
    "        continent_to_countries[continent].append((alpha_2, country.name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {code} due to error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7e40c24-e8b5-4227-b3eb-1b9d3f8fe084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:47.681640Z",
     "iopub.status.busy": "2025-06-14T16:15:47.681245Z",
     "iopub.status.idle": "2025-06-14T16:15:47.688806Z",
     "shell.execute_reply": "2025-06-14T16:15:47.688406Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_names(country, n=10):\n",
    "    names_dict = nd.get_top_names(n=n, country_alpha2=country)\n",
    "    names = []\n",
    "    if country in names_dict:\n",
    "        country_names = names_dict[country]\n",
    "        for gender in ['M', 'F']:\n",
    "            if gender in country_names:\n",
    "                names.extend(country_names[gender])\n",
    "    return list(set(names))\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tag_tokens(tokens, person_names):\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    for name in person_names:\n",
    "        name_tokens = name.split()\n",
    "        n_len = len(name_tokens)\n",
    "        for i in range(len(tokens) - n_len + 1):\n",
    "            if tokens[i:i + n_len] == name_tokens:\n",
    "                tags[i] = \"B-PER\"\n",
    "                for j in range(i + 1, i + n_len):\n",
    "                    tags[j] = \"I-PER\"\n",
    "    return tags\n",
    "\n",
    "\n",
    "def generate_challenge_dataset(num_samples=300):\n",
    "    dataset = []\n",
    "    failures = 0\n",
    "    max_failures = 1000\n",
    "\n",
    "    while len(dataset) < num_samples:\n",
    "        if failures >= max_failures:\n",
    "            print(f\"Stopped after {failures} failed attempts.\")\n",
    "            break\n",
    "\n",
    "        country = random.choice(chosen_countries)\n",
    "        names = get_names(country, n=10)\n",
    "\n",
    "        # Filter names: keep only those also in common_nouns\n",
    "        filtered_names = [\n",
    "            name for name in names if name.lower() in common_nouns]\n",
    "\n",
    "        if not filtered_names:\n",
    "            failures += 1\n",
    "            if failures % 10 == 0:\n",
    "                print(f\"{failures} failed attempts so far.\")\n",
    "            continue\n",
    "\n",
    "        # Pick one or two names as needed\n",
    "        if len(filtered_names) == 1:\n",
    "            name1 = filtered_names[0]\n",
    "            name2 = None\n",
    "        else:\n",
    "            name1, name2 = random.sample(filtered_names, 2)\n",
    "\n",
    "        template = random.choice(sentence_templates)\n",
    "\n",
    "        if \"{name2}\" in template and name2 is None:\n",
    "            sentence = template.format(name=name1, name2=name1)\n",
    "            person_names = [name1]\n",
    "        elif \"{name2}\" in template:\n",
    "            sentence = template.format(name=name1, name2=name2)\n",
    "            person_names = [name1, name2]\n",
    "        else:\n",
    "            sentence = template.format(name=name1)\n",
    "            person_names = [name1]\n",
    "\n",
    "        tokens = tokenize(sentence)\n",
    "        tags = tag_tokens(tokens, person_names)\n",
    "        dataset.append(list(zip(tokens, tags)))\n",
    "        print(len(dataset))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_to_csv(dataset, filepath=\"default_name.csv\"):\n",
    "    with open(filepath, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sentence_id\", \"token\", \"tag\"])\n",
    "        for idx, sentence in enumerate(dataset):\n",
    "            for token, tag in sentence:\n",
    "                writer.writerow([idx, token, tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba8822c-450b-4b4c-8c07-284e6bd814bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:47.690406Z",
     "iopub.status.busy": "2025-06-14T16:15:47.690170Z",
     "iopub.status.idle": "2025-06-14T16:15:47.694584Z",
     "shell.execute_reply": "2025-06-14T16:15:47.694174Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_csv(file, common=False):\n",
    "    print('evaluating', file)\n",
    "    scripted_challenge = pd.read_csv(file)\n",
    "\n",
    "    examples = []\n",
    "    for sentence_id, group in scripted_challenge.groupby(\"sentence_id\"):\n",
    "        tokens = group[\"token\"].tolist()\n",
    "        tags = group[\"tag\"].tolist()\n",
    "        examples.append({\"tokens\": tokens, \"ner_tags\": tags})\n",
    "\n",
    "    unique_tags = sorted(set(tag for ex in examples for tag in ex[\"ner_tags\"]))\n",
    "\n",
    "    for ex in examples:\n",
    "        ex[\"labels\"] = [conll_label_to_id[tag] for tag in ex[\"ner_tags\"]]\n",
    "\n",
    "    challenge_dataset = Dataset.from_list(examples)\n",
    "    tokenized = challenge_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "    a = trainer.predict(tokenized)\n",
    "\n",
    "    if common:\n",
    "        with open(f'./results/{model_name}_{train_data_name}_challenge_common.pkl', 'wb') as f:\n",
    "            pickle.dump(a, f)\n",
    "    else:\n",
    "        with open(f'./results/{model_name}_{train_data_name}_challenge_{file[:-3]}.pkl', 'wb') as f:\n",
    "            pickle.dump(a, f)\n",
    "\n",
    "    x, y = evaluate_predictions(a, tokenized)\n",
    "    print()\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "820fdce4-2e77-479b-b276-af5952269e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:15:47.696084Z",
     "iopub.status.busy": "2025-06-14T16:15:47.695872Z",
     "iopub.status.idle": "2025-06-14T16:16:31.274029Z",
     "shell.execute_reply": "2025-06-14T16:16:31.273421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating Asia_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6977.31 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6660.05 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8364.95 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8117.80 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.98      0.95      0.96      1134\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       1.00      1.00      1.00         6\n",
      "           O       1.00      0.98      0.99      9744\n",
      "\n",
      "    accuracy                           0.98     10884\n",
      "   macro avg       0.43      0.42      0.42     10884\n",
      "weighted avg       1.00      0.98      0.99     10884\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Europe_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7167.12 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6828.41 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8542.39 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8215.83 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.98      0.97      0.97      1136\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "           O       1.00      0.98      0.99      9682\n",
      "\n",
      "    accuracy                           0.98     10818\n",
      "   macro avg       0.40      0.39      0.39     10818\n",
      "weighted avg       1.00      0.98      0.99     10818\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Africa_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7079.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6771.35 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8194.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7963.06 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.97      0.95      0.96      1163\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       1.00      1.00      1.00         9\n",
      "           O       1.00      0.98      0.99      9682\n",
      "\n",
      "    accuracy                           0.98     10854\n",
      "   macro avg       0.50      0.49      0.49     10854\n",
      "weighted avg       1.00      0.98      0.99     10854\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating South America_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7105.71 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6784.41 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8444.19 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8175.17 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.99      0.98      0.98      1164\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-PER       1.00      1.00      1.00         2\n",
      "           O       1.00      0.98      0.99      9624\n",
      "\n",
      "    accuracy                           0.98     10790\n",
      "   macro avg       0.50      0.49      0.50     10790\n",
      "weighted avg       1.00      0.98      0.99     10790\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating North America_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7265.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6945.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8439.46 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8191.74 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.98      0.95      0.97      1145\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       I-ORG       0.00      0.00      0.00         0\n",
      "       I-PER       0.99      0.99      0.99        75\n",
      "           O       1.00      0.98      0.99      9569\n",
      "\n",
      "    accuracy                           0.98     10789\n",
      "   macro avg       0.42      0.42      0.42     10789\n",
      "weighted avg       1.00      0.98      0.99     10789\n",
      "\n",
      "\n",
      "------------------------------\n",
      "evaluating Oceania_ner_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7169.59 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6813.29 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8425.80 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8167.37 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       0.98      0.83      0.90      1148\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "           O       1.00      0.98      0.99      9548\n",
      "\n",
      "    accuracy                           0.96     10696\n",
      "   macro avg       0.40      0.36      0.38     10696\n",
      "weighted avg       1.00      0.96      0.98     10696\n",
      "\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in list(continent_to_code.keys()):\n",
    "    evaluate_csv(x+'_ner_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb2fde83-63c8-4b9f-8e0d-d84901a1491f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:31.276034Z",
     "iopub.status.busy": "2025-06-14T16:16:31.275728Z",
     "iopub.status.idle": "2025-06-14T16:16:38.235216Z",
     "shell.execute_reply": "2025-06-14T16:16:38.234677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ./common_nouns_challenge.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7762.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7360.74 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/guest/lre040/miniconda3/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8784.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 8439.75 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "       B-PER       1.00      0.89      0.94      1168\n",
      "           O       1.00      1.00      1.00      9336\n",
      "\n",
      "    accuracy                           0.99     10504\n",
      "   macro avg       0.40      0.38      0.39     10504\n",
      "weighted avg       1.00      0.99      0.99     10504\n",
      "\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate_csv('./common_nouns_challenge.csv', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfabcf97-8d56-46d3-823f-6a0e4ca90c6c",
   "metadata": {},
   "source": [
    "# Seed Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a4dd316-8556-4f45-8bcc-03c5da965b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:16:38.237363Z",
     "iopub.status.busy": "2025-06-14T16:16:38.236903Z",
     "iopub.status.idle": "2025-06-14T20:48:05.242203Z",
     "shell.execute_reply": "2025-06-14T20:48:05.241060Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 1:01:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   4%|▍         | 726/16595 [00:00<00:02, 7138.27 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1707/16595 [00:00<00:02, 5590.99 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2348/16595 [00:00<00:02, 4867.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4598.52 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  23%|██▎       | 3892/16595 [00:00<00:02, 5739.04 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4653/16595 [00:00<00:02, 5285.19 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5382/16595 [00:01<00:02, 4944.38 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 4722.61 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6933/16595 [00:01<00:01, 5785.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  47%|████▋     | 7870/16595 [00:01<00:01, 5765.05 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▎    | 8884/16595 [00:01<00:01, 5811.71 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9921/16595 [00:01<00:01, 5912.30 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10895/16595 [00:01<00:00, 5876.65 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11868/16595 [00:02<00:00, 5837.30 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12800/16595 [00:02<00:00, 5721.51 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13729/16595 [00:02<00:00, 5500.64 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14492/16595 [00:02<00:00, 5383.88 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15453/16595 [00:02<00:00, 5629.10 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16454/16595 [00:02<00:00, 5712.97 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4562.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.79      0.90      0.84      8535\n",
      "      B-MISC       0.76      0.69      0.72      4062\n",
      "       B-ORG       0.73      0.52      0.61      7398\n",
      "       B-PER       0.91      0.93      0.92      7975\n",
      "       I-LOC       0.60      0.77      0.67      1356\n",
      "      I-MISC       0.42      0.67      0.52      1380\n",
      "       I-ORG       0.63      0.76      0.69      4251\n",
      "       I-PER       0.87      0.99      0.92      5503\n",
      "           O       0.99      0.98      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.74      0.80      0.76    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 57:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.073300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   4%|▍         | 727/16595 [00:00<00:02, 7149.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1732/16595 [00:00<00:02, 5902.75 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2357/16595 [00:00<00:02, 5143.56 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4839.70 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▍       | 3950/16595 [00:00<00:02, 6120.06 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4667/16595 [00:00<00:02, 5609.86 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5384/16595 [00:00<00:02, 5214.57 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 5047.89 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6951/16595 [00:01<00:01, 6136.67 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  48%|████▊     | 7901/16595 [00:01<00:01, 6172.99 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▍    | 8921/16595 [00:01<00:01, 6217.02 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9936/16595 [00:01<00:01, 6289.89 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10941/16595 [00:01<00:00, 6212.39 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11895/16595 [00:02<00:00, 6199.03 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12827/16595 [00:02<00:00, 6058.33 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13755/16595 [00:02<00:00, 5819.57 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14502/16595 [00:02<00:00, 5710.56 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15499/16595 [00:02<00:00, 5985.16 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16475/16595 [00:02<00:00, 6100.36 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:04<00:00, 3859.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.90      0.84      8535\n",
      "      B-MISC       0.76      0.68      0.72      4062\n",
      "       B-ORG       0.73      0.52      0.61      7398\n",
      "       B-PER       0.92      0.93      0.92      7975\n",
      "       I-LOC       0.59      0.76      0.66      1356\n",
      "      I-MISC       0.41      0.68      0.51      1380\n",
      "       I-ORG       0.64      0.77      0.70      4251\n",
      "       I-PER       0.89      0.98      0.93      5503\n",
      "           O       0.99      0.98      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.75      0.80      0.76    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 48:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 780/16595 [00:00<00:02, 7676.61 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1714/16595 [00:00<00:02, 5985.53 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2353/16595 [00:00<00:02, 5220.28 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4917.61 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3928/16595 [00:00<00:02, 6131.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4672/16595 [00:00<00:02, 5637.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5391/16595 [00:00<00:02, 5249.66 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 5066.19 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6964/16595 [00:01<00:01, 6186.07 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  48%|████▊     | 7897/16595 [00:01<00:01, 6194.25 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▎    | 8918/16595 [00:01<00:01, 6260.51 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9934/16595 [00:01<00:01, 6318.10 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10935/16595 [00:01<00:00, 6384.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11890/16595 [00:01<00:00, 6330.95 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12817/16595 [00:02<00:00, 6145.07 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13742/16595 [00:02<00:00, 5854.22 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14519/16595 [00:02<00:00, 5787.81 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15465/16595 [00:02<00:00, 6025.79 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16482/16595 [00:02<00:00, 6191.83 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 5082.40 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.90      0.84      8535\n",
      "      B-MISC       0.75      0.69      0.72      4062\n",
      "       B-ORG       0.73      0.55      0.63      7398\n",
      "       B-PER       0.93      0.93      0.93      7975\n",
      "       I-LOC       0.60      0.76      0.67      1356\n",
      "      I-MISC       0.41      0.67      0.51      1380\n",
      "       I-ORG       0.63      0.77      0.69      4251\n",
      "       I-PER       0.90      0.97      0.94      5503\n",
      "           O       0.99      0.98      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.75      0.80      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 48:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   5%|▍         | 788/16595 [00:00<00:02, 7746.60 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  10%|█         | 1721/16595 [00:00<00:02, 5993.90 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  14%|█▍        | 2356/16595 [00:00<00:02, 5255.85 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  18%|█▊        | 3000/16595 [00:00<00:02, 4922.74 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  24%|██▎       | 3934/16595 [00:00<00:02, 6155.47 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  28%|██▊       | 4667/16595 [00:00<00:02, 5605.76 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  32%|███▏      | 5387/16595 [00:00<00:02, 5229.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  36%|███▌      | 6000/16595 [00:01<00:02, 5034.32 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  42%|████▏     | 6952/16595 [00:01<00:01, 6124.92 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  48%|████▊     | 7889/16595 [00:01<00:01, 6148.59 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  54%|█████▍    | 8928/16595 [00:01<00:01, 6182.11 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  60%|█████▉    | 9937/16595 [00:01<00:01, 6285.46 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  66%|██████▌   | 10927/16595 [00:01<00:00, 6320.29 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  72%|███████▏  | 11886/16595 [00:02<00:00, 6255.43 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  77%|███████▋  | 12830/16595 [00:02<00:00, 6089.71 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  83%|████████▎ | 13749/16595 [00:02<00:00, 5849.16 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  87%|████████▋ | 14491/16595 [00:02<00:00, 5709.84 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  93%|█████████▎| 15463/16595 [00:02<00:00, 5936.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  99%|█████████▉| 16462/16595 [00:02<00:00, 6058.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4833.96 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.90      0.83      8535\n",
      "      B-MISC       0.78      0.69      0.73      4062\n",
      "       B-ORG       0.71      0.50      0.59      7398\n",
      "       B-PER       0.91      0.93      0.92      7975\n",
      "       I-LOC       0.60      0.76      0.67      1356\n",
      "      I-MISC       0.46      0.68      0.55      1380\n",
      "       I-ORG       0.63      0.77      0.69      4251\n",
      "       I-PER       0.87      0.98      0.93      5503\n",
      "           O       0.99      0.98      0.99    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.75      0.80      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1051106/ipykernel_1402833/2779880192.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  seed_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11508' max='11508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11508/11508 47:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.069900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|          | 0/16595 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   4%|▎         | 606/16595 [00:00<00:02, 5962.40 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   8%|▊         | 1378/16595 [00:00<00:02, 5384.21 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  12%|█▏        | 2000/16595 [00:00<00:02, 4967.22 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  16%|█▌        | 2695/16595 [00:00<00:02, 5613.99 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  21%|██        | 3463/16595 [00:00<00:02, 5536.90 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  26%|██▌       | 4336/16595 [00:00<00:02, 5635.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  30%|███       | 4991/16595 [00:00<00:01, 5874.18 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  35%|███▍      | 5778/16595 [00:01<00:01, 5624.36 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  39%|███▉      | 6491/16595 [00:01<00:01, 5621.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  45%|████▌     | 7505/16595 [00:01<00:01, 6005.51 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  51%|█████     | 8464/16595 [00:01<00:01, 6080.54 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  57%|█████▋    | 9465/16595 [00:01<00:01, 6244.79 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  63%|██████▎   | 10467/16595 [00:01<00:00, 6361.48 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  69%|██████▉   | 11440/16595 [00:01<00:00, 6387.37 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  75%|███████▍  | 12409/16595 [00:02<00:00, 6308.47 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  81%|████████  | 13376/16595 [00:02<00:00, 6113.81 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  84%|████████▍ | 14000/16595 [00:02<00:00, 5753.42 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  90%|█████████ | 14984/16595 [00:02<00:00, 6666.27 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:  96%|█████████▋| 16000/16595 [00:02<00:00, 6143.23 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|██████████| 16595/16595 [00:03<00:00, 4998.24 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.79      0.90      0.84      8535\n",
      "      B-MISC       0.74      0.68      0.71      4062\n",
      "       B-ORG       0.73      0.51      0.60      7398\n",
      "       B-PER       0.94      0.92      0.93      7975\n",
      "       I-LOC       0.61      0.76      0.67      1356\n",
      "      I-MISC       0.40      0.69      0.51      1380\n",
      "       I-ORG       0.64      0.76      0.70      4251\n",
      "       I-PER       0.92      0.98      0.94      5503\n",
      "           O       0.99      0.98      0.98    201398\n",
      "\n",
      "    accuracy                           0.95    241858\n",
      "   macro avg       0.75      0.80      0.77    241858\n",
      "weighted avg       0.95      0.95      0.95    241858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [33, 42, 57, 106, 812, ]\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    seed_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(conll_label_to_id)\n",
    "    )\n",
    "\n",
    "    seed_args = TrainingArguments(\n",
    "        output_dir=f\"./output/{seed}\",\n",
    "        seed=seed,\n",
    "        eval_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "        logging_steps=1000,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    seed_trainer = Trainer(\n",
    "        model=seed_model,\n",
    "        args=seed_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    seed_trainer.train()\n",
    "\n",
    "    pred = seed_trainer.predict(test_data)\n",
    "\n",
    "    x, y = evaluate_predictions(pred, test_data)\n",
    "    eval_result = {'predictions': x, 'seed': seed}\n",
    "    results.append(eval_result)\n",
    "    with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9a317a-7bc8-4283-80e2-dc82360cbe9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:48:05.269343Z",
     "iopub.status.busy": "2025-06-14T20:48:05.269040Z",
     "iopub.status.idle": "2025-06-14T20:48:05.465487Z",
     "shell.execute_reply": "2025-06-14T20:48:05.464957Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'./results/{model_name}_{train_data_name}_seed_var_results.pkl', 'rb') as f:\n",
    "    seed_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c499fcf-70b1-46d4-b0b9-8217b0c17d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:48:05.467621Z",
     "iopub.status.busy": "2025-06-14T20:48:05.467345Z",
     "iopub.status.idle": "2025-06-14T20:48:09.920204Z",
     "shell.execute_reply": "2025-06-14T20:48:09.919739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 1: 0.958361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 2: 0.953546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 3: 0.955604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 0 and seed 4: 0.953293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 2: 0.957557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 3: 0.957041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 1 and seed 4: 0.956826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 2 and seed 3: 0.956336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 2 and seed 4: 0.955638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa between seed 3 and seed 4: 0.952905\n",
      "\n",
      "Average Cohen's kappa across all pairs: 0.955711\n"
     ]
    }
   ],
   "source": [
    "kappa_scores = []\n",
    "\n",
    "for i, j in combinations(range(len(seed_res)), 2):\n",
    "    preds_i = seed_res[i]['predictions']\n",
    "    preds_j = seed_res[j]['predictions']\n",
    "\n",
    "    kappa = cohen_kappa_score(preds_i, preds_j)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    print(f\"Cohen's kappa between seed {i} and seed {j}: {kappa:.6f}\")\n",
    "\n",
    "average_kappa = sum(kappa_scores) / len(kappa_scores)\n",
    "print(f\"\\nAverage Cohen's kappa across all pairs: {average_kappa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edf15a7d-d0a4-48fb-be53-2330aec4f100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T20:48:09.921962Z",
     "iopub.status.busy": "2025-06-14T20:48:09.921711Z",
     "iopub.status.idle": "2025-06-14T20:48:25.027832Z",
     "shell.execute_reply": "2025-06-14T20:48:25.027272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Krippendorff’s alpha (nominal): 0.9557\n"
     ]
    }
   ],
   "source": [
    "data = np.array([seed['predictions'] for seed in seed_res])\n",
    "\n",
    "alpha = krippendorff.alpha(reliability_data=data,\n",
    "                           level_of_measurement='nominal')\n",
    "\n",
    "print(f\"\\nKrippendorff’s alpha (nominal): {alpha:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
